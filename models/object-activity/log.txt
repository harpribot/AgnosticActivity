I1023 21:58:06.384521 37954 caffe.cpp:185] Using GPUs 0
I1023 21:58:06.390800 37954 caffe.cpp:190] GPU 0: Tesla K40m
I1023 21:58:06.647914 37954 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 500
base_lr: 0.01
display: 40
max_iter: 20000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 1000
snapshot_prefix: "models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train"
solver_mode: GPU
device_id: 0
net: "models/dissimilarity_siamese_net/train_val.prototxt"
I1023 21:58:06.650755 37954 solver.cpp:91] Creating training net from net file: models/dissimilarity_siamese_net/train_val.prototxt
I1023 21:58:06.654347 37954 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1023 21:58:06.654418 37954 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1023 21:58:06.655489 37954 net.cpp:49] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "examples/imagenet/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/work/03713/harshal1/maverick/vision_proj/data/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "fc7_n"
  type: "L2Norm"
  bottom: "fc7"
  top: "fc7_n"
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data"
  top: "conv1_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "conv1_p"
  top: "conv1_p"
}
layer {
  name: "norm1_p"
  type: "LRN"
  bottom: "conv1_p"
  top: "norm1_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "norm1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_p"
  type: "ReLU"
  bottom: "conv2_p"
  top: "conv2_p"
}
layer {
  name: "norm2_p"
  type: "LRN"
  bottom: "conv2_p"
  top: "norm2_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "norm2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_p"
  type: "Convolution"
  bottom: "pool2_p"
  top: "conv3_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_p"
  type: "ReLU"
  bottom: "conv3_p"
  top: "conv3_p"
}
layer {
  name: "conv4_p"
  type: "Convolution"
  bottom: "conv3_p"
  top: "conv4_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_p"
  type: "ReLU"
  bottom: "conv4_p"
  top: "conv4_p"
}
layer {
  name: "conv5_p"
  type: "Convolution"
  bottom: "conv4_p"
  top: "conv5_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_p"
  type: "ReLU"
  bottom: "conv5_p"
  top: "conv5_p"
}
layer {
  name: "pool5_p"
  type: "Pooling"
  bottom: "conv5_p"
  top: "pool5_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6_p"
  type: "InnerProduct"
  bottom: "pool5_p"
  top: "fc6_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6_p"
  type: "ReLU"
  bottom: "fc6_p"
  top: "fc6_p"
}
layer {
  name: "drop6_p"
  type: "Dropout"
  bottom: "fc6_p"
  top: "fc6_p"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_p"
  type: "InnerProduct"
  bottom: "fc6_p"
  top: "fc7_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7_p"
  type: "ReLU"
  bottom: "fc7_p"
  top: "fc7_p"
}
layer {
  name: "drop7_p"
  type: "Dropout"
  bottom: "fc7_p"
  top: "fc7_p"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_p"
  type: "InnerProduct"
  bottom: "fc7_p"
  top: "fc8_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 504
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_pn"
  type: "L2Norm"
  bottom: "fc7_p"
  top: "fc7_pn"
}
layer {
  name: "loss_p1"
  type: "EuclideanLoss"
  bottom: "fc7_n"
  bottom: "fc7_pn"
  top: "loss_p1"
  loss_weight: -0.35
}
layer {
  name: "loss_p2"
  type: "SoftmaxWithLoss"
  bottom: "fc8_p"
  bottom: "label"
  top: "loss_p2"
  loss_weight: 0.65
}
I1023 21:58:06.655886 37954 layer_factory.hpp:77] Creating layer data
I1023 21:58:06.656790 37954 net.cpp:91] Creating Layer data
I1023 21:58:06.656857 37954 net.cpp:399] data -> data
I1023 21:58:06.656950 37954 net.cpp:399] data -> label
I1023 21:58:06.656998 37954 data_transformer.cpp:25] Loading mean file from: examples/imagenet/imagenet_mean.binaryproto
I1023 21:58:06.668396 38065 db_lmdb.cpp:35] Opened lmdb /work/03713/harshal1/maverick/vision_proj/data/train_lmdb
I1023 21:58:06.680987 37954 data_layer.cpp:41] output data size: 256,3,227,227
I1023 21:58:06.989472 37954 net.cpp:141] Setting up data
I1023 21:58:06.989603 37954 net.cpp:148] Top shape: 256 3 227 227 (39574272)
I1023 21:58:06.989617 37954 net.cpp:148] Top shape: 256 (256)
I1023 21:58:06.989634 37954 net.cpp:156] Memory required for data: 158298112
I1023 21:58:06.989647 37954 layer_factory.hpp:77] Creating layer data_data_0_split
I1023 21:58:06.989693 37954 net.cpp:91] Creating Layer data_data_0_split
I1023 21:58:06.989724 37954 net.cpp:425] data_data_0_split <- data
I1023 21:58:06.989750 37954 net.cpp:399] data_data_0_split -> data_data_0_split_0
I1023 21:58:06.989776 37954 net.cpp:399] data_data_0_split -> data_data_0_split_1
I1023 21:58:06.989859 37954 net.cpp:141] Setting up data_data_0_split
I1023 21:58:06.989871 37954 net.cpp:148] Top shape: 256 3 227 227 (39574272)
I1023 21:58:06.989874 37954 net.cpp:148] Top shape: 256 3 227 227 (39574272)
I1023 21:58:06.989877 37954 net.cpp:156] Memory required for data: 474892288
I1023 21:58:06.989881 37954 layer_factory.hpp:77] Creating layer conv1
I1023 21:58:06.989936 37954 net.cpp:91] Creating Layer conv1
I1023 21:58:06.989945 37954 net.cpp:425] conv1 <- data_data_0_split_0
I1023 21:58:06.989953 37954 net.cpp:399] conv1 -> conv1
I1023 21:58:07.296790 37954 net.cpp:141] Setting up conv1
I1023 21:58:07.296834 37954 net.cpp:148] Top shape: 256 96 55 55 (74342400)
I1023 21:58:07.296839 37954 net.cpp:156] Memory required for data: 772261888
I1023 21:58:07.296916 37954 layer_factory.hpp:77] Creating layer relu1
I1023 21:58:07.296995 37954 net.cpp:91] Creating Layer relu1
I1023 21:58:07.297003 37954 net.cpp:425] relu1 <- conv1
I1023 21:58:07.297013 37954 net.cpp:386] relu1 -> conv1 (in-place)
I1023 21:58:07.297364 37954 net.cpp:141] Setting up relu1
I1023 21:58:07.297375 37954 net.cpp:148] Top shape: 256 96 55 55 (74342400)
I1023 21:58:07.297391 37954 net.cpp:156] Memory required for data: 1069631488
I1023 21:58:07.297394 37954 layer_factory.hpp:77] Creating layer norm1
I1023 21:58:07.297446 37954 net.cpp:91] Creating Layer norm1
I1023 21:58:07.297453 37954 net.cpp:425] norm1 <- conv1
I1023 21:58:07.297461 37954 net.cpp:399] norm1 -> norm1
I1023 21:58:07.297720 37954 net.cpp:141] Setting up norm1
I1023 21:58:07.297744 37954 net.cpp:148] Top shape: 256 96 55 55 (74342400)
I1023 21:58:07.297749 37954 net.cpp:156] Memory required for data: 1367001088
I1023 21:58:07.297751 37954 layer_factory.hpp:77] Creating layer pool1
I1023 21:58:07.297760 37954 net.cpp:91] Creating Layer pool1
I1023 21:58:07.297763 37954 net.cpp:425] pool1 <- norm1
I1023 21:58:07.297771 37954 net.cpp:399] pool1 -> pool1
I1023 21:58:07.297873 37954 net.cpp:141] Setting up pool1
I1023 21:58:07.297886 37954 net.cpp:148] Top shape: 256 96 27 27 (17915904)
I1023 21:58:07.297889 37954 net.cpp:156] Memory required for data: 1438664704
I1023 21:58:07.297894 37954 layer_factory.hpp:77] Creating layer conv2
I1023 21:58:07.297909 37954 net.cpp:91] Creating Layer conv2
I1023 21:58:07.297914 37954 net.cpp:425] conv2 <- pool1
I1023 21:58:07.297921 37954 net.cpp:399] conv2 -> conv2
I1023 21:58:07.304678 37954 net.cpp:141] Setting up conv2
I1023 21:58:07.304692 37954 net.cpp:148] Top shape: 256 256 27 27 (47775744)
I1023 21:58:07.304707 37954 net.cpp:156] Memory required for data: 1629767680
I1023 21:58:07.304715 37954 layer_factory.hpp:77] Creating layer relu2
I1023 21:58:07.304723 37954 net.cpp:91] Creating Layer relu2
I1023 21:58:07.304726 37954 net.cpp:425] relu2 <- conv2
I1023 21:58:07.304734 37954 net.cpp:386] relu2 -> conv2 (in-place)
I1023 21:58:07.304885 37954 net.cpp:141] Setting up relu2
I1023 21:58:07.304898 37954 net.cpp:148] Top shape: 256 256 27 27 (47775744)
I1023 21:58:07.304900 37954 net.cpp:156] Memory required for data: 1820870656
I1023 21:58:07.304903 37954 layer_factory.hpp:77] Creating layer norm2
I1023 21:58:07.304911 37954 net.cpp:91] Creating Layer norm2
I1023 21:58:07.304914 37954 net.cpp:425] norm2 <- conv2
I1023 21:58:07.304922 37954 net.cpp:399] norm2 -> norm2
I1023 21:58:07.305220 37954 net.cpp:141] Setting up norm2
I1023 21:58:07.305244 37954 net.cpp:148] Top shape: 256 256 27 27 (47775744)
I1023 21:58:07.305248 37954 net.cpp:156] Memory required for data: 2011973632
I1023 21:58:07.305250 37954 layer_factory.hpp:77] Creating layer pool2
I1023 21:58:07.305259 37954 net.cpp:91] Creating Layer pool2
I1023 21:58:07.305263 37954 net.cpp:425] pool2 <- norm2
I1023 21:58:07.305269 37954 net.cpp:399] pool2 -> pool2
I1023 21:58:07.305317 37954 net.cpp:141] Setting up pool2
I1023 21:58:07.305325 37954 net.cpp:148] Top shape: 256 256 13 13 (11075584)
I1023 21:58:07.305326 37954 net.cpp:156] Memory required for data: 2056275968
I1023 21:58:07.305330 37954 layer_factory.hpp:77] Creating layer conv3
I1023 21:58:07.305341 37954 net.cpp:91] Creating Layer conv3
I1023 21:58:07.305346 37954 net.cpp:425] conv3 <- pool2
I1023 21:58:07.305353 37954 net.cpp:399] conv3 -> conv3
I1023 21:58:07.329948 37954 net.cpp:141] Setting up conv3
I1023 21:58:07.329974 37954 net.cpp:148] Top shape: 256 384 13 13 (16613376)
I1023 21:58:07.329978 37954 net.cpp:156] Memory required for data: 2122729472
I1023 21:58:07.329988 37954 layer_factory.hpp:77] Creating layer relu3
I1023 21:58:07.329995 37954 net.cpp:91] Creating Layer relu3
I1023 21:58:07.329998 37954 net.cpp:425] relu3 <- conv3
I1023 21:58:07.330006 37954 net.cpp:386] relu3 -> conv3 (in-place)
I1023 21:58:07.330153 37954 net.cpp:141] Setting up relu3
I1023 21:58:07.330164 37954 net.cpp:148] Top shape: 256 384 13 13 (16613376)
I1023 21:58:07.330168 37954 net.cpp:156] Memory required for data: 2189182976
I1023 21:58:07.330171 37954 layer_factory.hpp:77] Creating layer conv4
I1023 21:58:07.330198 37954 net.cpp:91] Creating Layer conv4
I1023 21:58:07.330201 37954 net.cpp:425] conv4 <- conv3
I1023 21:58:07.330210 37954 net.cpp:399] conv4 -> conv4
I1023 21:58:07.341505 37954 net.cpp:141] Setting up conv4
I1023 21:58:07.341522 37954 net.cpp:148] Top shape: 256 384 13 13 (16613376)
I1023 21:58:07.341538 37954 net.cpp:156] Memory required for data: 2255636480
I1023 21:58:07.341545 37954 layer_factory.hpp:77] Creating layer relu4
I1023 21:58:07.341555 37954 net.cpp:91] Creating Layer relu4
I1023 21:58:07.341560 37954 net.cpp:425] relu4 <- conv4
I1023 21:58:07.341565 37954 net.cpp:386] relu4 -> conv4 (in-place)
I1023 21:58:07.341719 37954 net.cpp:141] Setting up relu4
I1023 21:58:07.341732 37954 net.cpp:148] Top shape: 256 384 13 13 (16613376)
I1023 21:58:07.341734 37954 net.cpp:156] Memory required for data: 2322089984
I1023 21:58:07.341738 37954 layer_factory.hpp:77] Creating layer conv5
I1023 21:58:07.341752 37954 net.cpp:91] Creating Layer conv5
I1023 21:58:07.341755 37954 net.cpp:425] conv5 <- conv4
I1023 21:58:07.341761 37954 net.cpp:399] conv5 -> conv5
I1023 21:58:07.350016 37954 net.cpp:141] Setting up conv5
I1023 21:58:07.350030 37954 net.cpp:148] Top shape: 256 256 13 13 (11075584)
I1023 21:58:07.350046 37954 net.cpp:156] Memory required for data: 2366392320
I1023 21:58:07.350057 37954 layer_factory.hpp:77] Creating layer relu5
I1023 21:58:07.350065 37954 net.cpp:91] Creating Layer relu5
I1023 21:58:07.350069 37954 net.cpp:425] relu5 <- conv5
I1023 21:58:07.350076 37954 net.cpp:386] relu5 -> conv5 (in-place)
I1023 21:58:07.350229 37954 net.cpp:141] Setting up relu5
I1023 21:58:07.350242 37954 net.cpp:148] Top shape: 256 256 13 13 (11075584)
I1023 21:58:07.350245 37954 net.cpp:156] Memory required for data: 2410694656
I1023 21:58:07.350250 37954 layer_factory.hpp:77] Creating layer pool5
I1023 21:58:07.350260 37954 net.cpp:91] Creating Layer pool5
I1023 21:58:07.350262 37954 net.cpp:425] pool5 <- conv5
I1023 21:58:07.350281 37954 net.cpp:399] pool5 -> pool5
I1023 21:58:07.350325 37954 net.cpp:141] Setting up pool5
I1023 21:58:07.350333 37954 net.cpp:148] Top shape: 256 256 6 6 (2359296)
I1023 21:58:07.350337 37954 net.cpp:156] Memory required for data: 2420131840
I1023 21:58:07.350340 37954 layer_factory.hpp:77] Creating layer fc6
I1023 21:58:07.350352 37954 net.cpp:91] Creating Layer fc6
I1023 21:58:07.350355 37954 net.cpp:425] fc6 <- pool5
I1023 21:58:07.350363 37954 net.cpp:399] fc6 -> fc6
I1023 21:58:07.888516 37954 net.cpp:141] Setting up fc6
I1023 21:58:07.888561 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:07.888566 37954 net.cpp:156] Memory required for data: 2424326144
I1023 21:58:07.888576 37954 layer_factory.hpp:77] Creating layer relu6
I1023 21:58:07.888588 37954 net.cpp:91] Creating Layer relu6
I1023 21:58:07.888593 37954 net.cpp:425] relu6 <- fc6
I1023 21:58:07.888600 37954 net.cpp:386] relu6 -> fc6 (in-place)
I1023 21:58:07.889051 37954 net.cpp:141] Setting up relu6
I1023 21:58:07.889062 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:07.889065 37954 net.cpp:156] Memory required for data: 2428520448
I1023 21:58:07.889070 37954 layer_factory.hpp:77] Creating layer drop6
I1023 21:58:07.889153 37954 net.cpp:91] Creating Layer drop6
I1023 21:58:07.889161 37954 net.cpp:425] drop6 <- fc6
I1023 21:58:07.889170 37954 net.cpp:386] drop6 -> fc6 (in-place)
I1023 21:58:07.889238 37954 net.cpp:141] Setting up drop6
I1023 21:58:07.889247 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:07.889250 37954 net.cpp:156] Memory required for data: 2432714752
I1023 21:58:07.889253 37954 layer_factory.hpp:77] Creating layer fc7
I1023 21:58:07.889266 37954 net.cpp:91] Creating Layer fc7
I1023 21:58:07.889269 37954 net.cpp:425] fc7 <- fc6
I1023 21:58:07.889276 37954 net.cpp:399] fc7 -> fc7
I1023 21:58:08.123859 37954 net.cpp:141] Setting up fc7
I1023 21:58:08.123909 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:08.123914 37954 net.cpp:156] Memory required for data: 2436909056
I1023 21:58:08.123925 37954 layer_factory.hpp:77] Creating layer fc7_n
I1023 21:58:08.124040 37954 net.cpp:91] Creating Layer fc7_n
I1023 21:58:08.124047 37954 net.cpp:425] fc7_n <- fc7
I1023 21:58:08.124056 37954 net.cpp:399] fc7_n -> fc7_n
I1023 21:58:08.124092 37954 net.cpp:141] Setting up fc7_n
I1023 21:58:08.124101 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:08.124104 37954 net.cpp:156] Memory required for data: 2441103360
I1023 21:58:08.124109 37954 layer_factory.hpp:77] Creating layer conv1_p
I1023 21:58:08.124121 37954 net.cpp:91] Creating Layer conv1_p
I1023 21:58:08.124125 37954 net.cpp:425] conv1_p <- data_data_0_split_1
I1023 21:58:08.124132 37954 net.cpp:399] conv1_p -> conv1_p
I1023 21:58:08.125790 37954 net.cpp:141] Setting up conv1_p
I1023 21:58:08.125802 37954 net.cpp:148] Top shape: 256 96 55 55 (74342400)
I1023 21:58:08.125807 37954 net.cpp:156] Memory required for data: 2738472960
I1023 21:58:08.125813 37954 layer_factory.hpp:77] Creating layer relu1_p
I1023 21:58:08.125819 37954 net.cpp:91] Creating Layer relu1_p
I1023 21:58:08.125823 37954 net.cpp:425] relu1_p <- conv1_p
I1023 21:58:08.125830 37954 net.cpp:386] relu1_p -> conv1_p (in-place)
I1023 21:58:08.125979 37954 net.cpp:141] Setting up relu1_p
I1023 21:58:08.125989 37954 net.cpp:148] Top shape: 256 96 55 55 (74342400)
I1023 21:58:08.125994 37954 net.cpp:156] Memory required for data: 3035842560
I1023 21:58:08.125998 37954 layer_factory.hpp:77] Creating layer norm1_p
I1023 21:58:08.126005 37954 net.cpp:91] Creating Layer norm1_p
I1023 21:58:08.126009 37954 net.cpp:425] norm1_p <- conv1_p
I1023 21:58:08.126014 37954 net.cpp:399] norm1_p -> norm1_p
I1023 21:58:08.126317 37954 net.cpp:141] Setting up norm1_p
I1023 21:58:08.126327 37954 net.cpp:148] Top shape: 256 96 55 55 (74342400)
I1023 21:58:08.126330 37954 net.cpp:156] Memory required for data: 3333212160
I1023 21:58:08.126333 37954 layer_factory.hpp:77] Creating layer pool1_p
I1023 21:58:08.126340 37954 net.cpp:91] Creating Layer pool1_p
I1023 21:58:08.126344 37954 net.cpp:425] pool1_p <- norm1_p
I1023 21:58:08.126350 37954 net.cpp:399] pool1_p -> pool1_p
I1023 21:58:08.126399 37954 net.cpp:141] Setting up pool1_p
I1023 21:58:08.126405 37954 net.cpp:148] Top shape: 256 96 27 27 (17915904)
I1023 21:58:08.126408 37954 net.cpp:156] Memory required for data: 3404875776
I1023 21:58:08.126411 37954 layer_factory.hpp:77] Creating layer conv2_p
I1023 21:58:08.126425 37954 net.cpp:91] Creating Layer conv2_p
I1023 21:58:08.126428 37954 net.cpp:425] conv2_p <- pool1_p
I1023 21:58:08.126433 37954 net.cpp:399] conv2_p -> conv2_p
I1023 21:58:08.132150 37954 net.cpp:141] Setting up conv2_p
I1023 21:58:08.132161 37954 net.cpp:148] Top shape: 256 256 27 27 (47775744)
I1023 21:58:08.132176 37954 net.cpp:156] Memory required for data: 3595978752
I1023 21:58:08.132186 37954 layer_factory.hpp:77] Creating layer relu2_p
I1023 21:58:08.132195 37954 net.cpp:91] Creating Layer relu2_p
I1023 21:58:08.132200 37954 net.cpp:425] relu2_p <- conv2_p
I1023 21:58:08.132205 37954 net.cpp:386] relu2_p -> conv2_p (in-place)
I1023 21:58:08.132458 37954 net.cpp:141] Setting up relu2_p
I1023 21:58:08.132470 37954 net.cpp:148] Top shape: 256 256 27 27 (47775744)
I1023 21:58:08.132473 37954 net.cpp:156] Memory required for data: 3787081728
I1023 21:58:08.132477 37954 layer_factory.hpp:77] Creating layer norm2_p
I1023 21:58:08.132484 37954 net.cpp:91] Creating Layer norm2_p
I1023 21:58:08.132488 37954 net.cpp:425] norm2_p <- conv2_p
I1023 21:58:08.132494 37954 net.cpp:399] norm2_p -> norm2_p
I1023 21:58:08.132679 37954 net.cpp:141] Setting up norm2_p
I1023 21:58:08.132701 37954 net.cpp:148] Top shape: 256 256 27 27 (47775744)
I1023 21:58:08.132705 37954 net.cpp:156] Memory required for data: 3978184704
I1023 21:58:08.132709 37954 layer_factory.hpp:77] Creating layer pool2_p
I1023 21:58:08.132717 37954 net.cpp:91] Creating Layer pool2_p
I1023 21:58:08.132721 37954 net.cpp:425] pool2_p <- norm2_p
I1023 21:58:08.132726 37954 net.cpp:399] pool2_p -> pool2_p
I1023 21:58:08.132764 37954 net.cpp:141] Setting up pool2_p
I1023 21:58:08.132771 37954 net.cpp:148] Top shape: 256 256 13 13 (11075584)
I1023 21:58:08.132791 37954 net.cpp:156] Memory required for data: 4022487040
I1023 21:58:08.132794 37954 layer_factory.hpp:77] Creating layer conv3_p
I1023 21:58:08.132807 37954 net.cpp:91] Creating Layer conv3_p
I1023 21:58:08.132812 37954 net.cpp:425] conv3_p <- pool2_p
I1023 21:58:08.132819 37954 net.cpp:399] conv3_p -> conv3_p
I1023 21:58:08.146144 37954 net.cpp:141] Setting up conv3_p
I1023 21:58:08.146155 37954 net.cpp:148] Top shape: 256 384 13 13 (16613376)
I1023 21:58:08.146170 37954 net.cpp:156] Memory required for data: 4088940544
I1023 21:58:08.146176 37954 layer_factory.hpp:77] Creating layer relu3_p
I1023 21:58:08.146186 37954 net.cpp:91] Creating Layer relu3_p
I1023 21:58:08.146190 37954 net.cpp:425] relu3_p <- conv3_p
I1023 21:58:08.146195 37954 net.cpp:386] relu3_p -> conv3_p (in-place)
I1023 21:58:08.146450 37954 net.cpp:141] Setting up relu3_p
I1023 21:58:08.146461 37954 net.cpp:148] Top shape: 256 384 13 13 (16613376)
I1023 21:58:08.146463 37954 net.cpp:156] Memory required for data: 4155394048
I1023 21:58:08.146467 37954 layer_factory.hpp:77] Creating layer conv4_p
I1023 21:58:08.146483 37954 net.cpp:91] Creating Layer conv4_p
I1023 21:58:08.146488 37954 net.cpp:425] conv4_p <- conv3_p
I1023 21:58:08.146494 37954 net.cpp:399] conv4_p -> conv4_p
I1023 21:58:08.157302 37954 net.cpp:141] Setting up conv4_p
I1023 21:58:08.157328 37954 net.cpp:148] Top shape: 256 384 13 13 (16613376)
I1023 21:58:08.157332 37954 net.cpp:156] Memory required for data: 4221847552
I1023 21:58:08.157338 37954 layer_factory.hpp:77] Creating layer relu4_p
I1023 21:58:08.157346 37954 net.cpp:91] Creating Layer relu4_p
I1023 21:58:08.157348 37954 net.cpp:425] relu4_p <- conv4_p
I1023 21:58:08.157353 37954 net.cpp:386] relu4_p -> conv4_p (in-place)
I1023 21:58:08.157604 37954 net.cpp:141] Setting up relu4_p
I1023 21:58:08.157620 37954 net.cpp:148] Top shape: 256 384 13 13 (16613376)
I1023 21:58:08.157624 37954 net.cpp:156] Memory required for data: 4288301056
I1023 21:58:08.157640 37954 layer_factory.hpp:77] Creating layer conv5_p
I1023 21:58:08.157652 37954 net.cpp:91] Creating Layer conv5_p
I1023 21:58:08.157657 37954 net.cpp:425] conv5_p <- conv4_p
I1023 21:58:08.157663 37954 net.cpp:399] conv5_p -> conv5_p
I1023 21:58:08.165331 37954 net.cpp:141] Setting up conv5_p
I1023 21:58:08.165356 37954 net.cpp:148] Top shape: 256 256 13 13 (11075584)
I1023 21:58:08.165360 37954 net.cpp:156] Memory required for data: 4332603392
I1023 21:58:08.165366 37954 layer_factory.hpp:77] Creating layer relu5_p
I1023 21:58:08.165372 37954 net.cpp:91] Creating Layer relu5_p
I1023 21:58:08.165376 37954 net.cpp:425] relu5_p <- conv5_p
I1023 21:58:08.165381 37954 net.cpp:386] relu5_p -> conv5_p (in-place)
I1023 21:58:08.165643 37954 net.cpp:141] Setting up relu5_p
I1023 21:58:08.165653 37954 net.cpp:148] Top shape: 256 256 13 13 (11075584)
I1023 21:58:08.165657 37954 net.cpp:156] Memory required for data: 4376905728
I1023 21:58:08.165660 37954 layer_factory.hpp:77] Creating layer pool5_p
I1023 21:58:08.165668 37954 net.cpp:91] Creating Layer pool5_p
I1023 21:58:08.165671 37954 net.cpp:425] pool5_p <- conv5_p
I1023 21:58:08.165678 37954 net.cpp:399] pool5_p -> pool5_p
I1023 21:58:08.165733 37954 net.cpp:141] Setting up pool5_p
I1023 21:58:08.165745 37954 net.cpp:148] Top shape: 256 256 6 6 (2359296)
I1023 21:58:08.165747 37954 net.cpp:156] Memory required for data: 4386342912
I1023 21:58:08.165750 37954 layer_factory.hpp:77] Creating layer fc6_p
I1023 21:58:08.165771 37954 net.cpp:91] Creating Layer fc6_p
I1023 21:58:08.165776 37954 net.cpp:425] fc6_p <- pool5_p
I1023 21:58:08.165782 37954 net.cpp:399] fc6_p -> fc6_p
I1023 21:58:08.698952 37954 net.cpp:141] Setting up fc6_p
I1023 21:58:08.698997 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:08.699002 37954 net.cpp:156] Memory required for data: 4390537216
I1023 21:58:08.699012 37954 layer_factory.hpp:77] Creating layer relu6_p
I1023 21:58:08.699026 37954 net.cpp:91] Creating Layer relu6_p
I1023 21:58:08.699031 37954 net.cpp:425] relu6_p <- fc6_p
I1023 21:58:08.699076 37954 net.cpp:386] relu6_p -> fc6_p (in-place)
I1023 21:58:08.699549 37954 net.cpp:141] Setting up relu6_p
I1023 21:58:08.699571 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:08.699574 37954 net.cpp:156] Memory required for data: 4394731520
I1023 21:58:08.699579 37954 layer_factory.hpp:77] Creating layer drop6_p
I1023 21:58:08.699589 37954 net.cpp:91] Creating Layer drop6_p
I1023 21:58:08.699594 37954 net.cpp:425] drop6_p <- fc6_p
I1023 21:58:08.699597 37954 net.cpp:386] drop6_p -> fc6_p (in-place)
I1023 21:58:08.699625 37954 net.cpp:141] Setting up drop6_p
I1023 21:58:08.699633 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:08.699636 37954 net.cpp:156] Memory required for data: 4398925824
I1023 21:58:08.699640 37954 layer_factory.hpp:77] Creating layer fc7_p
I1023 21:58:08.699650 37954 net.cpp:91] Creating Layer fc7_p
I1023 21:58:08.699652 37954 net.cpp:425] fc7_p <- fc6_p
I1023 21:58:08.699659 37954 net.cpp:399] fc7_p -> fc7_p
I1023 21:58:08.935555 37954 net.cpp:141] Setting up fc7_p
I1023 21:58:08.935603 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:08.935611 37954 net.cpp:156] Memory required for data: 4403120128
I1023 21:58:08.935621 37954 layer_factory.hpp:77] Creating layer relu7_p
I1023 21:58:08.935633 37954 net.cpp:91] Creating Layer relu7_p
I1023 21:58:08.935638 37954 net.cpp:425] relu7_p <- fc7_p
I1023 21:58:08.935647 37954 net.cpp:386] relu7_p -> fc7_p (in-place)
I1023 21:58:08.935881 37954 net.cpp:141] Setting up relu7_p
I1023 21:58:08.935890 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:08.935894 37954 net.cpp:156] Memory required for data: 4407314432
I1023 21:58:08.935897 37954 layer_factory.hpp:77] Creating layer drop7_p
I1023 21:58:08.935907 37954 net.cpp:91] Creating Layer drop7_p
I1023 21:58:08.935911 37954 net.cpp:425] drop7_p <- fc7_p
I1023 21:58:08.935916 37954 net.cpp:386] drop7_p -> fc7_p (in-place)
I1023 21:58:08.935940 37954 net.cpp:141] Setting up drop7_p
I1023 21:58:08.935948 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:08.935951 37954 net.cpp:156] Memory required for data: 4411508736
I1023 21:58:08.935956 37954 layer_factory.hpp:77] Creating layer fc7_p_drop7_p_0_split
I1023 21:58:08.935961 37954 net.cpp:91] Creating Layer fc7_p_drop7_p_0_split
I1023 21:58:08.935977 37954 net.cpp:425] fc7_p_drop7_p_0_split <- fc7_p
I1023 21:58:08.935982 37954 net.cpp:399] fc7_p_drop7_p_0_split -> fc7_p_drop7_p_0_split_0
I1023 21:58:08.935991 37954 net.cpp:399] fc7_p_drop7_p_0_split -> fc7_p_drop7_p_0_split_1
I1023 21:58:08.936028 37954 net.cpp:141] Setting up fc7_p_drop7_p_0_split
I1023 21:58:08.936035 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:08.936038 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:08.936041 37954 net.cpp:156] Memory required for data: 4419897344
I1023 21:58:08.936044 37954 layer_factory.hpp:77] Creating layer fc8_p
I1023 21:58:08.936055 37954 net.cpp:91] Creating Layer fc8_p
I1023 21:58:08.936059 37954 net.cpp:425] fc8_p <- fc7_p_drop7_p_0_split_0
I1023 21:58:08.936064 37954 net.cpp:399] fc8_p -> fc8_p
I1023 21:58:08.964948 37954 net.cpp:141] Setting up fc8_p
I1023 21:58:08.964972 37954 net.cpp:148] Top shape: 256 504 (129024)
I1023 21:58:08.964975 37954 net.cpp:156] Memory required for data: 4420413440
I1023 21:58:08.964982 37954 layer_factory.hpp:77] Creating layer fc7_pn
I1023 21:58:08.964990 37954 net.cpp:91] Creating Layer fc7_pn
I1023 21:58:08.964994 37954 net.cpp:425] fc7_pn <- fc7_p_drop7_p_0_split_1
I1023 21:58:08.964999 37954 net.cpp:399] fc7_pn -> fc7_pn
I1023 21:58:08.965028 37954 net.cpp:141] Setting up fc7_pn
I1023 21:58:08.965034 37954 net.cpp:148] Top shape: 256 4096 (1048576)
I1023 21:58:08.965037 37954 net.cpp:156] Memory required for data: 4424607744
I1023 21:58:08.965040 37954 layer_factory.hpp:77] Creating layer loss_p1
I1023 21:58:08.965097 37954 net.cpp:91] Creating Layer loss_p1
I1023 21:58:08.965106 37954 net.cpp:425] loss_p1 <- fc7_n
I1023 21:58:08.965111 37954 net.cpp:425] loss_p1 <- fc7_pn
I1023 21:58:08.965116 37954 net.cpp:399] loss_p1 -> loss_p1
I1023 21:58:08.965231 37954 net.cpp:141] Setting up loss_p1
I1023 21:58:08.965241 37954 net.cpp:148] Top shape: (1)
I1023 21:58:08.965245 37954 net.cpp:151]     with loss weight -0.35
I1023 21:58:08.965322 37954 net.cpp:156] Memory required for data: 4424607748
I1023 21:58:08.965327 37954 layer_factory.hpp:77] Creating layer loss_p2
I1023 21:58:08.965366 37954 net.cpp:91] Creating Layer loss_p2
I1023 21:58:08.965373 37954 net.cpp:425] loss_p2 <- fc8_p
I1023 21:58:08.965378 37954 net.cpp:425] loss_p2 <- label
I1023 21:58:08.965384 37954 net.cpp:399] loss_p2 -> loss_p2
I1023 21:58:08.965425 37954 layer_factory.hpp:77] Creating layer loss_p2
I1023 21:58:08.966512 37954 net.cpp:141] Setting up loss_p2
I1023 21:58:08.966534 37954 net.cpp:148] Top shape: (1)
I1023 21:58:08.966537 37954 net.cpp:151]     with loss weight 0.65
I1023 21:58:08.966543 37954 net.cpp:156] Memory required for data: 4424607752
I1023 21:58:08.966547 37954 net.cpp:217] loss_p2 needs backward computation.
I1023 21:58:08.966552 37954 net.cpp:217] loss_p1 needs backward computation.
I1023 21:58:08.966554 37954 net.cpp:217] fc7_pn needs backward computation.
I1023 21:58:08.966557 37954 net.cpp:217] fc8_p needs backward computation.
I1023 21:58:08.966560 37954 net.cpp:217] fc7_p_drop7_p_0_split needs backward computation.
I1023 21:58:08.966563 37954 net.cpp:217] drop7_p needs backward computation.
I1023 21:58:08.966565 37954 net.cpp:217] relu7_p needs backward computation.
I1023 21:58:08.966568 37954 net.cpp:217] fc7_p needs backward computation.
I1023 21:58:08.966572 37954 net.cpp:217] drop6_p needs backward computation.
I1023 21:58:08.966574 37954 net.cpp:217] relu6_p needs backward computation.
I1023 21:58:08.966576 37954 net.cpp:217] fc6_p needs backward computation.
I1023 21:58:08.966579 37954 net.cpp:217] pool5_p needs backward computation.
I1023 21:58:08.966583 37954 net.cpp:217] relu5_p needs backward computation.
I1023 21:58:08.966586 37954 net.cpp:217] conv5_p needs backward computation.
I1023 21:58:08.966589 37954 net.cpp:217] relu4_p needs backward computation.
I1023 21:58:08.966593 37954 net.cpp:217] conv4_p needs backward computation.
I1023 21:58:08.966595 37954 net.cpp:217] relu3_p needs backward computation.
I1023 21:58:08.966598 37954 net.cpp:217] conv3_p needs backward computation.
I1023 21:58:08.966601 37954 net.cpp:217] pool2_p needs backward computation.
I1023 21:58:08.966604 37954 net.cpp:217] norm2_p needs backward computation.
I1023 21:58:08.966612 37954 net.cpp:217] relu2_p needs backward computation.
I1023 21:58:08.966615 37954 net.cpp:217] conv2_p needs backward computation.
I1023 21:58:08.966619 37954 net.cpp:217] pool1_p needs backward computation.
I1023 21:58:08.966621 37954 net.cpp:217] norm1_p needs backward computation.
I1023 21:58:08.966637 37954 net.cpp:217] relu1_p needs backward computation.
I1023 21:58:08.966639 37954 net.cpp:217] conv1_p needs backward computation.
I1023 21:58:08.966644 37954 net.cpp:219] fc7_n does not need backward computation.
I1023 21:58:08.966646 37954 net.cpp:219] fc7 does not need backward computation.
I1023 21:58:08.966650 37954 net.cpp:219] drop6 does not need backward computation.
I1023 21:58:08.966653 37954 net.cpp:219] relu6 does not need backward computation.
I1023 21:58:08.966656 37954 net.cpp:219] fc6 does not need backward computation.
I1023 21:58:08.966660 37954 net.cpp:219] pool5 does not need backward computation.
I1023 21:58:08.966662 37954 net.cpp:219] relu5 does not need backward computation.
I1023 21:58:08.966665 37954 net.cpp:219] conv5 does not need backward computation.
I1023 21:58:08.966670 37954 net.cpp:219] relu4 does not need backward computation.
I1023 21:58:08.966672 37954 net.cpp:219] conv4 does not need backward computation.
I1023 21:58:08.966675 37954 net.cpp:219] relu3 does not need backward computation.
I1023 21:58:08.966678 37954 net.cpp:219] conv3 does not need backward computation.
I1023 21:58:08.966681 37954 net.cpp:219] pool2 does not need backward computation.
I1023 21:58:08.966686 37954 net.cpp:219] norm2 does not need backward computation.
I1023 21:58:08.966701 37954 net.cpp:219] relu2 does not need backward computation.
I1023 21:58:08.966706 37954 net.cpp:219] conv2 does not need backward computation.
I1023 21:58:08.966711 37954 net.cpp:219] pool1 does not need backward computation.
I1023 21:58:08.966716 37954 net.cpp:219] norm1 does not need backward computation.
I1023 21:58:08.966719 37954 net.cpp:219] relu1 does not need backward computation.
I1023 21:58:08.966722 37954 net.cpp:219] conv1 does not need backward computation.
I1023 21:58:08.966725 37954 net.cpp:219] data_data_0_split does not need backward computation.
I1023 21:58:08.966729 37954 net.cpp:219] data does not need backward computation.
I1023 21:58:08.966732 37954 net.cpp:261] This network produces output loss_p1
I1023 21:58:08.966735 37954 net.cpp:261] This network produces output loss_p2
I1023 21:58:08.966763 37954 net.cpp:274] Network initialization done.
I1023 21:58:08.970366 37954 solver.cpp:181] Creating test net (#0) specified by net file: models/dissimilarity_siamese_net/train_val.prototxt
I1023 21:58:08.970448 37954 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1023 21:58:08.971549 37954 net.cpp:49] Initializing net from parameters: 
name: "AlexNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "examples/imagenet/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/work/03713/harshal1/maverick/vision_proj/data/val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "conv1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "norm1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "conv2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "norm2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "fc7_n"
  type: "L2Norm"
  bottom: "fc7"
  top: "fc7_n"
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data"
  top: "conv1_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "conv1_p"
  top: "conv1_p"
}
layer {
  name: "norm1_p"
  type: "LRN"
  bottom: "conv1_p"
  top: "norm1_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "norm1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_p"
  type: "ReLU"
  bottom: "conv2_p"
  top: "conv2_p"
}
layer {
  name: "norm2_p"
  type: "LRN"
  bottom: "conv2_p"
  top: "norm2_p"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "norm2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3_p"
  type: "Convolution"
  bottom: "pool2_p"
  top: "conv3_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_p"
  type: "ReLU"
  bottom: "conv3_p"
  top: "conv3_p"
}
layer {
  name: "conv4_p"
  type: "Convolution"
  bottom: "conv3_p"
  top: "conv4_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_p"
  type: "ReLU"
  bottom: "conv4_p"
  top: "conv4_p"
}
layer {
  name: "conv5_p"
  type: "Convolution"
  bottom: "conv4_p"
  top: "conv5_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_p"
  type: "ReLU"
  bottom: "conv5_p"
  top: "conv5_p"
}
layer {
  name: "pool5_p"
  type: "Pooling"
  bottom: "conv5_p"
  top: "pool5_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6_p"
  type: "InnerProduct"
  bottom: "pool5_p"
  top: "fc6_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6_p"
  type: "ReLU"
  bottom: "fc6_p"
  top: "fc6_p"
}
layer {
  name: "drop6_p"
  type: "Dropout"
  bottom: "fc6_p"
  top: "fc6_p"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7_p"
  type: "InnerProduct"
  bottom: "fc6_p"
  top: "fc7_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7_p"
  type: "ReLU"
  bottom: "fc7_p"
  top: "fc7_p"
}
layer {
  name: "drop7_p"
  type: "Dropout"
  bottom: "fc7_p"
  top: "fc7_p"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_p"
  type: "InnerProduct"
  bottom: "fc7_p"
  top: "fc8_p"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 504
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_p"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "fc7_pn"
  type: "L2Norm"
  bottom: "fc7_p"
  top: "fc7_pn"
}
layer {
  name: "loss_p1"
  type: "EuclideanLoss"
  bottom: "fc7_n"
  bottom: "fc7_pn"
  top: "loss_p1"
  loss_weight: -0.35
}
layer {
  name: "loss_p2"
  type: "SoftmaxWithLoss"
  bottom: "fc8_p"
  bottom: "label"
  top: "loss_p2"
  loss_weight: 0.65
}
I1023 21:58:08.971768 37954 layer_factory.hpp:77] Creating layer data
I1023 21:58:08.971909 37954 net.cpp:91] Creating Layer data
I1023 21:58:08.971917 37954 net.cpp:399] data -> data
I1023 21:58:08.971931 37954 net.cpp:399] data -> label
I1023 21:58:08.971952 37954 data_transformer.cpp:25] Loading mean file from: examples/imagenet/imagenet_mean.binaryproto
I1023 21:58:08.983469 38067 db_lmdb.cpp:35] Opened lmdb /work/03713/harshal1/maverick/vision_proj/data/val_lmdb
I1023 21:58:08.984741 37954 data_layer.cpp:41] output data size: 50,3,227,227
I1023 21:58:09.042963 37954 net.cpp:141] Setting up data
I1023 21:58:09.042996 37954 net.cpp:148] Top shape: 50 3 227 227 (7729350)
I1023 21:58:09.043002 37954 net.cpp:148] Top shape: 50 (50)
I1023 21:58:09.043005 37954 net.cpp:156] Memory required for data: 30917600
I1023 21:58:09.043025 37954 layer_factory.hpp:77] Creating layer data_data_0_split
I1023 21:58:09.043042 37954 net.cpp:91] Creating Layer data_data_0_split
I1023 21:58:09.043047 37954 net.cpp:425] data_data_0_split <- data
I1023 21:58:09.043056 37954 net.cpp:399] data_data_0_split -> data_data_0_split_0
I1023 21:58:09.043068 37954 net.cpp:399] data_data_0_split -> data_data_0_split_1
I1023 21:58:09.043164 37954 net.cpp:141] Setting up data_data_0_split
I1023 21:58:09.043172 37954 net.cpp:148] Top shape: 50 3 227 227 (7729350)
I1023 21:58:09.043177 37954 net.cpp:148] Top shape: 50 3 227 227 (7729350)
I1023 21:58:09.043179 37954 net.cpp:156] Memory required for data: 92752400
I1023 21:58:09.043184 37954 layer_factory.hpp:77] Creating layer label_data_1_split
I1023 21:58:09.043193 37954 net.cpp:91] Creating Layer label_data_1_split
I1023 21:58:09.043238 37954 net.cpp:425] label_data_1_split <- label
I1023 21:58:09.043246 37954 net.cpp:399] label_data_1_split -> label_data_1_split_0
I1023 21:58:09.043252 37954 net.cpp:399] label_data_1_split -> label_data_1_split_1
I1023 21:58:09.043296 37954 net.cpp:141] Setting up label_data_1_split
I1023 21:58:09.043306 37954 net.cpp:148] Top shape: 50 (50)
I1023 21:58:09.043310 37954 net.cpp:148] Top shape: 50 (50)
I1023 21:58:09.043313 37954 net.cpp:156] Memory required for data: 92752800
I1023 21:58:09.043316 37954 layer_factory.hpp:77] Creating layer conv1
I1023 21:58:09.043331 37954 net.cpp:91] Creating Layer conv1
I1023 21:58:09.043335 37954 net.cpp:425] conv1 <- data_data_0_split_0
I1023 21:58:09.043342 37954 net.cpp:399] conv1 -> conv1
I1023 21:58:09.047790 37954 net.cpp:141] Setting up conv1
I1023 21:58:09.047814 37954 net.cpp:148] Top shape: 50 96 55 55 (14520000)
I1023 21:58:09.047818 37954 net.cpp:156] Memory required for data: 150832800
I1023 21:58:09.047830 37954 layer_factory.hpp:77] Creating layer relu1
I1023 21:58:09.047839 37954 net.cpp:91] Creating Layer relu1
I1023 21:58:09.047843 37954 net.cpp:425] relu1 <- conv1
I1023 21:58:09.047848 37954 net.cpp:386] relu1 -> conv1 (in-place)
I1023 21:58:09.048115 37954 net.cpp:141] Setting up relu1
I1023 21:58:09.048125 37954 net.cpp:148] Top shape: 50 96 55 55 (14520000)
I1023 21:58:09.048130 37954 net.cpp:156] Memory required for data: 208912800
I1023 21:58:09.048133 37954 layer_factory.hpp:77] Creating layer norm1
I1023 21:58:09.048142 37954 net.cpp:91] Creating Layer norm1
I1023 21:58:09.048146 37954 net.cpp:425] norm1 <- conv1
I1023 21:58:09.048152 37954 net.cpp:399] norm1 -> norm1
I1023 21:58:09.048444 37954 net.cpp:141] Setting up norm1
I1023 21:58:09.048467 37954 net.cpp:148] Top shape: 50 96 55 55 (14520000)
I1023 21:58:09.048470 37954 net.cpp:156] Memory required for data: 266992800
I1023 21:58:09.048475 37954 layer_factory.hpp:77] Creating layer pool1
I1023 21:58:09.048482 37954 net.cpp:91] Creating Layer pool1
I1023 21:58:09.048485 37954 net.cpp:425] pool1 <- norm1
I1023 21:58:09.048491 37954 net.cpp:399] pool1 -> pool1
I1023 21:58:09.048547 37954 net.cpp:141] Setting up pool1
I1023 21:58:09.048553 37954 net.cpp:148] Top shape: 50 96 27 27 (3499200)
I1023 21:58:09.048557 37954 net.cpp:156] Memory required for data: 280989600
I1023 21:58:09.048559 37954 layer_factory.hpp:77] Creating layer conv2
I1023 21:58:09.048570 37954 net.cpp:91] Creating Layer conv2
I1023 21:58:09.048574 37954 net.cpp:425] conv2 <- pool1
I1023 21:58:09.048581 37954 net.cpp:399] conv2 -> conv2
I1023 21:58:09.054791 37954 net.cpp:141] Setting up conv2
I1023 21:58:09.054817 37954 net.cpp:148] Top shape: 50 256 27 27 (9331200)
I1023 21:58:09.054821 37954 net.cpp:156] Memory required for data: 318314400
I1023 21:58:09.054831 37954 layer_factory.hpp:77] Creating layer relu2
I1023 21:58:09.054839 37954 net.cpp:91] Creating Layer relu2
I1023 21:58:09.054843 37954 net.cpp:425] relu2 <- conv2
I1023 21:58:09.054849 37954 net.cpp:386] relu2 -> conv2 (in-place)
I1023 21:58:09.055124 37954 net.cpp:141] Setting up relu2
I1023 21:58:09.055136 37954 net.cpp:148] Top shape: 50 256 27 27 (9331200)
I1023 21:58:09.055140 37954 net.cpp:156] Memory required for data: 355639200
I1023 21:58:09.055143 37954 layer_factory.hpp:77] Creating layer norm2
I1023 21:58:09.055151 37954 net.cpp:91] Creating Layer norm2
I1023 21:58:09.055155 37954 net.cpp:425] norm2 <- conv2
I1023 21:58:09.055161 37954 net.cpp:399] norm2 -> norm2
I1023 21:58:09.055348 37954 net.cpp:141] Setting up norm2
I1023 21:58:09.055361 37954 net.cpp:148] Top shape: 50 256 27 27 (9331200)
I1023 21:58:09.055364 37954 net.cpp:156] Memory required for data: 392964000
I1023 21:58:09.055368 37954 layer_factory.hpp:77] Creating layer pool2
I1023 21:58:09.055375 37954 net.cpp:91] Creating Layer pool2
I1023 21:58:09.055379 37954 net.cpp:425] pool2 <- norm2
I1023 21:58:09.055385 37954 net.cpp:399] pool2 -> pool2
I1023 21:58:09.055428 37954 net.cpp:141] Setting up pool2
I1023 21:58:09.055435 37954 net.cpp:148] Top shape: 50 256 13 13 (2163200)
I1023 21:58:09.055454 37954 net.cpp:156] Memory required for data: 401616800
I1023 21:58:09.055459 37954 layer_factory.hpp:77] Creating layer conv3
I1023 21:58:09.055469 37954 net.cpp:91] Creating Layer conv3
I1023 21:58:09.055474 37954 net.cpp:425] conv3 <- pool2
I1023 21:58:09.055481 37954 net.cpp:399] conv3 -> conv3
I1023 21:58:09.070246 37954 net.cpp:141] Setting up conv3
I1023 21:58:09.070287 37954 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I1023 21:58:09.070292 37954 net.cpp:156] Memory required for data: 414596000
I1023 21:58:09.070307 37954 layer_factory.hpp:77] Creating layer relu3
I1023 21:58:09.070319 37954 net.cpp:91] Creating Layer relu3
I1023 21:58:09.070324 37954 net.cpp:425] relu3 <- conv3
I1023 21:58:09.070333 37954 net.cpp:386] relu3 -> conv3 (in-place)
I1023 21:58:09.070616 37954 net.cpp:141] Setting up relu3
I1023 21:58:09.070627 37954 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I1023 21:58:09.070631 37954 net.cpp:156] Memory required for data: 427575200
I1023 21:58:09.070636 37954 layer_factory.hpp:77] Creating layer conv4
I1023 21:58:09.070662 37954 net.cpp:91] Creating Layer conv4
I1023 21:58:09.070665 37954 net.cpp:425] conv4 <- conv3
I1023 21:58:09.070673 37954 net.cpp:399] conv4 -> conv4
I1023 21:58:09.082355 37954 net.cpp:141] Setting up conv4
I1023 21:58:09.082382 37954 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I1023 21:58:09.082386 37954 net.cpp:156] Memory required for data: 440554400
I1023 21:58:09.082393 37954 layer_factory.hpp:77] Creating layer relu4
I1023 21:58:09.082401 37954 net.cpp:91] Creating Layer relu4
I1023 21:58:09.082406 37954 net.cpp:425] relu4 <- conv4
I1023 21:58:09.082412 37954 net.cpp:386] relu4 -> conv4 (in-place)
I1023 21:58:09.082705 37954 net.cpp:141] Setting up relu4
I1023 21:58:09.082717 37954 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I1023 21:58:09.082721 37954 net.cpp:156] Memory required for data: 453533600
I1023 21:58:09.082726 37954 layer_factory.hpp:77] Creating layer conv5
I1023 21:58:09.082737 37954 net.cpp:91] Creating Layer conv5
I1023 21:58:09.082741 37954 net.cpp:425] conv5 <- conv4
I1023 21:58:09.082749 37954 net.cpp:399] conv5 -> conv5
I1023 21:58:09.091084 37954 net.cpp:141] Setting up conv5
I1023 21:58:09.091099 37954 net.cpp:148] Top shape: 50 256 13 13 (2163200)
I1023 21:58:09.091115 37954 net.cpp:156] Memory required for data: 462186400
I1023 21:58:09.091127 37954 layer_factory.hpp:77] Creating layer relu5
I1023 21:58:09.091138 37954 net.cpp:91] Creating Layer relu5
I1023 21:58:09.091142 37954 net.cpp:425] relu5 <- conv5
I1023 21:58:09.091148 37954 net.cpp:386] relu5 -> conv5 (in-place)
I1023 21:58:09.091414 37954 net.cpp:141] Setting up relu5
I1023 21:58:09.091425 37954 net.cpp:148] Top shape: 50 256 13 13 (2163200)
I1023 21:58:09.091429 37954 net.cpp:156] Memory required for data: 470839200
I1023 21:58:09.091433 37954 layer_factory.hpp:77] Creating layer pool5
I1023 21:58:09.091441 37954 net.cpp:91] Creating Layer pool5
I1023 21:58:09.091445 37954 net.cpp:425] pool5 <- conv5
I1023 21:58:09.091452 37954 net.cpp:399] pool5 -> pool5
I1023 21:58:09.091501 37954 net.cpp:141] Setting up pool5
I1023 21:58:09.091509 37954 net.cpp:148] Top shape: 50 256 6 6 (460800)
I1023 21:58:09.091512 37954 net.cpp:156] Memory required for data: 472682400
I1023 21:58:09.091516 37954 layer_factory.hpp:77] Creating layer fc6
I1023 21:58:09.091526 37954 net.cpp:91] Creating Layer fc6
I1023 21:58:09.091531 37954 net.cpp:425] fc6 <- pool5
I1023 21:58:09.091536 37954 net.cpp:399] fc6 -> fc6
I1023 21:58:09.627846 37954 net.cpp:141] Setting up fc6
I1023 21:58:09.627893 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:09.627897 37954 net.cpp:156] Memory required for data: 473501600
I1023 21:58:09.627907 37954 layer_factory.hpp:77] Creating layer relu6
I1023 21:58:09.627920 37954 net.cpp:91] Creating Layer relu6
I1023 21:58:09.627926 37954 net.cpp:425] relu6 <- fc6
I1023 21:58:09.627934 37954 net.cpp:386] relu6 -> fc6 (in-place)
I1023 21:58:09.628154 37954 net.cpp:141] Setting up relu6
I1023 21:58:09.628162 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:09.628201 37954 net.cpp:156] Memory required for data: 474320800
I1023 21:58:09.628204 37954 layer_factory.hpp:77] Creating layer drop6
I1023 21:58:09.628214 37954 net.cpp:91] Creating Layer drop6
I1023 21:58:09.628217 37954 net.cpp:425] drop6 <- fc6
I1023 21:58:09.628223 37954 net.cpp:386] drop6 -> fc6 (in-place)
I1023 21:58:09.628257 37954 net.cpp:141] Setting up drop6
I1023 21:58:09.628263 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:09.628267 37954 net.cpp:156] Memory required for data: 475140000
I1023 21:58:09.628269 37954 layer_factory.hpp:77] Creating layer fc7
I1023 21:58:09.628279 37954 net.cpp:91] Creating Layer fc7
I1023 21:58:09.628283 37954 net.cpp:425] fc7 <- fc6
I1023 21:58:09.628288 37954 net.cpp:399] fc7 -> fc7
I1023 21:58:09.864272 37954 net.cpp:141] Setting up fc7
I1023 21:58:09.864317 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:09.864321 37954 net.cpp:156] Memory required for data: 475959200
I1023 21:58:09.864331 37954 layer_factory.hpp:77] Creating layer fc7_n
I1023 21:58:09.864343 37954 net.cpp:91] Creating Layer fc7_n
I1023 21:58:09.864348 37954 net.cpp:425] fc7_n <- fc7
I1023 21:58:09.864357 37954 net.cpp:399] fc7_n -> fc7_n
I1023 21:58:09.864393 37954 net.cpp:141] Setting up fc7_n
I1023 21:58:09.864400 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:09.864403 37954 net.cpp:156] Memory required for data: 476778400
I1023 21:58:09.864406 37954 layer_factory.hpp:77] Creating layer conv1_p
I1023 21:58:09.864420 37954 net.cpp:91] Creating Layer conv1_p
I1023 21:58:09.864424 37954 net.cpp:425] conv1_p <- data_data_0_split_1
I1023 21:58:09.864431 37954 net.cpp:399] conv1_p -> conv1_p
I1023 21:58:09.866075 37954 net.cpp:141] Setting up conv1_p
I1023 21:58:09.866099 37954 net.cpp:148] Top shape: 50 96 55 55 (14520000)
I1023 21:58:09.866102 37954 net.cpp:156] Memory required for data: 534858400
I1023 21:58:09.866108 37954 layer_factory.hpp:77] Creating layer relu1_p
I1023 21:58:09.866117 37954 net.cpp:91] Creating Layer relu1_p
I1023 21:58:09.866122 37954 net.cpp:425] relu1_p <- conv1_p
I1023 21:58:09.866127 37954 net.cpp:386] relu1_p -> conv1_p (in-place)
I1023 21:58:09.866384 37954 net.cpp:141] Setting up relu1_p
I1023 21:58:09.866394 37954 net.cpp:148] Top shape: 50 96 55 55 (14520000)
I1023 21:58:09.866396 37954 net.cpp:156] Memory required for data: 592938400
I1023 21:58:09.866400 37954 layer_factory.hpp:77] Creating layer norm1_p
I1023 21:58:09.866410 37954 net.cpp:91] Creating Layer norm1_p
I1023 21:58:09.866413 37954 net.cpp:425] norm1_p <- conv1_p
I1023 21:58:09.866420 37954 net.cpp:399] norm1_p -> norm1_p
I1023 21:58:09.866593 37954 net.cpp:141] Setting up norm1_p
I1023 21:58:09.866603 37954 net.cpp:148] Top shape: 50 96 55 55 (14520000)
I1023 21:58:09.866610 37954 net.cpp:156] Memory required for data: 651018400
I1023 21:58:09.866614 37954 layer_factory.hpp:77] Creating layer pool1_p
I1023 21:58:09.866634 37954 net.cpp:91] Creating Layer pool1_p
I1023 21:58:09.866638 37954 net.cpp:425] pool1_p <- norm1_p
I1023 21:58:09.866644 37954 net.cpp:399] pool1_p -> pool1_p
I1023 21:58:09.866688 37954 net.cpp:141] Setting up pool1_p
I1023 21:58:09.866696 37954 net.cpp:148] Top shape: 50 96 27 27 (3499200)
I1023 21:58:09.866699 37954 net.cpp:156] Memory required for data: 665015200
I1023 21:58:09.866703 37954 layer_factory.hpp:77] Creating layer conv2_p
I1023 21:58:09.866714 37954 net.cpp:91] Creating Layer conv2_p
I1023 21:58:09.866729 37954 net.cpp:425] conv2_p <- pool1_p
I1023 21:58:09.866736 37954 net.cpp:399] conv2_p -> conv2_p
I1023 21:58:09.872711 37954 net.cpp:141] Setting up conv2_p
I1023 21:58:09.872723 37954 net.cpp:148] Top shape: 50 256 27 27 (9331200)
I1023 21:58:09.872740 37954 net.cpp:156] Memory required for data: 702340000
I1023 21:58:09.872752 37954 layer_factory.hpp:77] Creating layer relu2_p
I1023 21:58:09.872759 37954 net.cpp:91] Creating Layer relu2_p
I1023 21:58:09.872763 37954 net.cpp:425] relu2_p <- conv2_p
I1023 21:58:09.872769 37954 net.cpp:386] relu2_p -> conv2_p (in-place)
I1023 21:58:09.872930 37954 net.cpp:141] Setting up relu2_p
I1023 21:58:09.872973 37954 net.cpp:148] Top shape: 50 256 27 27 (9331200)
I1023 21:58:09.872977 37954 net.cpp:156] Memory required for data: 739664800
I1023 21:58:09.872980 37954 layer_factory.hpp:77] Creating layer norm2_p
I1023 21:58:09.872987 37954 net.cpp:91] Creating Layer norm2_p
I1023 21:58:09.872990 37954 net.cpp:425] norm2_p <- conv2_p
I1023 21:58:09.872997 37954 net.cpp:399] norm2_p -> norm2_p
I1023 21:58:09.873291 37954 net.cpp:141] Setting up norm2_p
I1023 21:58:09.873301 37954 net.cpp:148] Top shape: 50 256 27 27 (9331200)
I1023 21:58:09.873303 37954 net.cpp:156] Memory required for data: 776989600
I1023 21:58:09.873306 37954 layer_factory.hpp:77] Creating layer pool2_p
I1023 21:58:09.873316 37954 net.cpp:91] Creating Layer pool2_p
I1023 21:58:09.873319 37954 net.cpp:425] pool2_p <- norm2_p
I1023 21:58:09.873325 37954 net.cpp:399] pool2_p -> pool2_p
I1023 21:58:09.873368 37954 net.cpp:141] Setting up pool2_p
I1023 21:58:09.873376 37954 net.cpp:148] Top shape: 50 256 13 13 (2163200)
I1023 21:58:09.873379 37954 net.cpp:156] Memory required for data: 785642400
I1023 21:58:09.873383 37954 layer_factory.hpp:77] Creating layer conv3_p
I1023 21:58:09.873392 37954 net.cpp:91] Creating Layer conv3_p
I1023 21:58:09.873395 37954 net.cpp:425] conv3_p <- pool2_p
I1023 21:58:09.873404 37954 net.cpp:399] conv3_p -> conv3_p
I1023 21:58:09.886890 37954 net.cpp:141] Setting up conv3_p
I1023 21:58:09.886915 37954 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I1023 21:58:09.886919 37954 net.cpp:156] Memory required for data: 798621600
I1023 21:58:09.886925 37954 layer_factory.hpp:77] Creating layer relu3_p
I1023 21:58:09.886937 37954 net.cpp:91] Creating Layer relu3_p
I1023 21:58:09.886941 37954 net.cpp:425] relu3_p <- conv3_p
I1023 21:58:09.886946 37954 net.cpp:386] relu3_p -> conv3_p (in-place)
I1023 21:58:09.887097 37954 net.cpp:141] Setting up relu3_p
I1023 21:58:09.887106 37954 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I1023 21:58:09.887109 37954 net.cpp:156] Memory required for data: 811600800
I1023 21:58:09.887112 37954 layer_factory.hpp:77] Creating layer conv4_p
I1023 21:58:09.887125 37954 net.cpp:91] Creating Layer conv4_p
I1023 21:58:09.887130 37954 net.cpp:425] conv4_p <- conv3_p
I1023 21:58:09.887135 37954 net.cpp:399] conv4_p -> conv4_p
I1023 21:58:09.898105 37954 net.cpp:141] Setting up conv4_p
I1023 21:58:09.898116 37954 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I1023 21:58:09.898133 37954 net.cpp:156] Memory required for data: 824580000
I1023 21:58:09.898138 37954 layer_factory.hpp:77] Creating layer relu4_p
I1023 21:58:09.898147 37954 net.cpp:91] Creating Layer relu4_p
I1023 21:58:09.898151 37954 net.cpp:425] relu4_p <- conv4_p
I1023 21:58:09.898156 37954 net.cpp:386] relu4_p -> conv4_p (in-place)
I1023 21:58:09.898311 37954 net.cpp:141] Setting up relu4_p
I1023 21:58:09.898321 37954 net.cpp:148] Top shape: 50 384 13 13 (3244800)
I1023 21:58:09.898324 37954 net.cpp:156] Memory required for data: 837559200
I1023 21:58:09.898327 37954 layer_factory.hpp:77] Creating layer conv5_p
I1023 21:58:09.898339 37954 net.cpp:91] Creating Layer conv5_p
I1023 21:58:09.898342 37954 net.cpp:425] conv5_p <- conv4_p
I1023 21:58:09.898350 37954 net.cpp:399] conv5_p -> conv5_p
I1023 21:58:09.906211 37954 net.cpp:141] Setting up conv5_p
I1023 21:58:09.906234 37954 net.cpp:148] Top shape: 50 256 13 13 (2163200)
I1023 21:58:09.906239 37954 net.cpp:156] Memory required for data: 846212000
I1023 21:58:09.906244 37954 layer_factory.hpp:77] Creating layer relu5_p
I1023 21:58:09.906252 37954 net.cpp:91] Creating Layer relu5_p
I1023 21:58:09.906256 37954 net.cpp:425] relu5_p <- conv5_p
I1023 21:58:09.906261 37954 net.cpp:386] relu5_p -> conv5_p (in-place)
I1023 21:58:09.906415 37954 net.cpp:141] Setting up relu5_p
I1023 21:58:09.906424 37954 net.cpp:148] Top shape: 50 256 13 13 (2163200)
I1023 21:58:09.906427 37954 net.cpp:156] Memory required for data: 854864800
I1023 21:58:09.906430 37954 layer_factory.hpp:77] Creating layer pool5_p
I1023 21:58:09.906436 37954 net.cpp:91] Creating Layer pool5_p
I1023 21:58:09.906453 37954 net.cpp:425] pool5_p <- conv5_p
I1023 21:58:09.906461 37954 net.cpp:399] pool5_p -> pool5_p
I1023 21:58:09.906508 37954 net.cpp:141] Setting up pool5_p
I1023 21:58:09.906517 37954 net.cpp:148] Top shape: 50 256 6 6 (460800)
I1023 21:58:09.906519 37954 net.cpp:156] Memory required for data: 856708000
I1023 21:58:09.906522 37954 layer_factory.hpp:77] Creating layer fc6_p
I1023 21:58:09.906534 37954 net.cpp:91] Creating Layer fc6_p
I1023 21:58:09.906538 37954 net.cpp:425] fc6_p <- pool5_p
I1023 21:58:09.906544 37954 net.cpp:399] fc6_p -> fc6_p
I1023 21:58:10.438700 37954 net.cpp:141] Setting up fc6_p
I1023 21:58:10.438745 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:10.438750 37954 net.cpp:156] Memory required for data: 857527200
I1023 21:58:10.438761 37954 layer_factory.hpp:77] Creating layer relu6_p
I1023 21:58:10.438776 37954 net.cpp:91] Creating Layer relu6_p
I1023 21:58:10.438782 37954 net.cpp:425] relu6_p <- fc6_p
I1023 21:58:10.438791 37954 net.cpp:386] relu6_p -> fc6_p (in-place)
I1023 21:58:10.439265 37954 net.cpp:141] Setting up relu6_p
I1023 21:58:10.439275 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:10.439277 37954 net.cpp:156] Memory required for data: 858346400
I1023 21:58:10.439292 37954 layer_factory.hpp:77] Creating layer drop6_p
I1023 21:58:10.439302 37954 net.cpp:91] Creating Layer drop6_p
I1023 21:58:10.439306 37954 net.cpp:425] drop6_p <- fc6_p
I1023 21:58:10.439311 37954 net.cpp:386] drop6_p -> fc6_p (in-place)
I1023 21:58:10.439347 37954 net.cpp:141] Setting up drop6_p
I1023 21:58:10.439354 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:10.439357 37954 net.cpp:156] Memory required for data: 859165600
I1023 21:58:10.439359 37954 layer_factory.hpp:77] Creating layer fc7_p
I1023 21:58:10.439371 37954 net.cpp:91] Creating Layer fc7_p
I1023 21:58:10.439374 37954 net.cpp:425] fc7_p <- fc6_p
I1023 21:58:10.439380 37954 net.cpp:399] fc7_p -> fc7_p
I1023 21:58:10.675925 37954 net.cpp:141] Setting up fc7_p
I1023 21:58:10.675958 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:10.675962 37954 net.cpp:156] Memory required for data: 859984800
I1023 21:58:10.675972 37954 layer_factory.hpp:77] Creating layer relu7_p
I1023 21:58:10.675987 37954 net.cpp:91] Creating Layer relu7_p
I1023 21:58:10.675993 37954 net.cpp:425] relu7_p <- fc7_p
I1023 21:58:10.676000 37954 net.cpp:386] relu7_p -> fc7_p (in-place)
I1023 21:58:10.676483 37954 net.cpp:141] Setting up relu7_p
I1023 21:58:10.676493 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:10.676509 37954 net.cpp:156] Memory required for data: 860804000
I1023 21:58:10.676513 37954 layer_factory.hpp:77] Creating layer drop7_p
I1023 21:58:10.676522 37954 net.cpp:91] Creating Layer drop7_p
I1023 21:58:10.676525 37954 net.cpp:425] drop7_p <- fc7_p
I1023 21:58:10.676530 37954 net.cpp:386] drop7_p -> fc7_p (in-place)
I1023 21:58:10.676565 37954 net.cpp:141] Setting up drop7_p
I1023 21:58:10.676573 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:10.676575 37954 net.cpp:156] Memory required for data: 861623200
I1023 21:58:10.676578 37954 layer_factory.hpp:77] Creating layer fc7_p_drop7_p_0_split
I1023 21:58:10.676585 37954 net.cpp:91] Creating Layer fc7_p_drop7_p_0_split
I1023 21:58:10.676589 37954 net.cpp:425] fc7_p_drop7_p_0_split <- fc7_p
I1023 21:58:10.676595 37954 net.cpp:399] fc7_p_drop7_p_0_split -> fc7_p_drop7_p_0_split_0
I1023 21:58:10.676604 37954 net.cpp:399] fc7_p_drop7_p_0_split -> fc7_p_drop7_p_0_split_1
I1023 21:58:10.676669 37954 net.cpp:141] Setting up fc7_p_drop7_p_0_split
I1023 21:58:10.676678 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:10.676683 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:10.676686 37954 net.cpp:156] Memory required for data: 863261600
I1023 21:58:10.676689 37954 layer_factory.hpp:77] Creating layer fc8_p
I1023 21:58:10.676699 37954 net.cpp:91] Creating Layer fc8_p
I1023 21:58:10.676702 37954 net.cpp:425] fc8_p <- fc7_p_drop7_p_0_split_0
I1023 21:58:10.676723 37954 net.cpp:399] fc8_p -> fc8_p
I1023 21:58:10.705524 37954 net.cpp:141] Setting up fc8_p
I1023 21:58:10.705569 37954 net.cpp:148] Top shape: 50 504 (25200)
I1023 21:58:10.705584 37954 net.cpp:156] Memory required for data: 863362400
I1023 21:58:10.705590 37954 layer_factory.hpp:77] Creating layer fc8_p_fc8_p_0_split
I1023 21:58:10.705598 37954 net.cpp:91] Creating Layer fc8_p_fc8_p_0_split
I1023 21:58:10.705602 37954 net.cpp:425] fc8_p_fc8_p_0_split <- fc8_p
I1023 21:58:10.705610 37954 net.cpp:399] fc8_p_fc8_p_0_split -> fc8_p_fc8_p_0_split_0
I1023 21:58:10.705618 37954 net.cpp:399] fc8_p_fc8_p_0_split -> fc8_p_fc8_p_0_split_1
I1023 21:58:10.705660 37954 net.cpp:141] Setting up fc8_p_fc8_p_0_split
I1023 21:58:10.705668 37954 net.cpp:148] Top shape: 50 504 (25200)
I1023 21:58:10.705684 37954 net.cpp:148] Top shape: 50 504 (25200)
I1023 21:58:10.705687 37954 net.cpp:156] Memory required for data: 863564000
I1023 21:58:10.705690 37954 layer_factory.hpp:77] Creating layer accuracy
I1023 21:58:10.705765 37954 net.cpp:91] Creating Layer accuracy
I1023 21:58:10.705772 37954 net.cpp:425] accuracy <- fc8_p_fc8_p_0_split_0
I1023 21:58:10.705778 37954 net.cpp:425] accuracy <- label_data_1_split_0
I1023 21:58:10.705786 37954 net.cpp:399] accuracy -> accuracy
I1023 21:58:10.705844 37954 net.cpp:141] Setting up accuracy
I1023 21:58:10.705853 37954 net.cpp:148] Top shape: (1)
I1023 21:58:10.705857 37954 net.cpp:156] Memory required for data: 863564004
I1023 21:58:10.705860 37954 layer_factory.hpp:77] Creating layer fc7_pn
I1023 21:58:10.705868 37954 net.cpp:91] Creating Layer fc7_pn
I1023 21:58:10.705870 37954 net.cpp:425] fc7_pn <- fc7_p_drop7_p_0_split_1
I1023 21:58:10.705876 37954 net.cpp:399] fc7_pn -> fc7_pn
I1023 21:58:10.705907 37954 net.cpp:141] Setting up fc7_pn
I1023 21:58:10.705914 37954 net.cpp:148] Top shape: 50 4096 (204800)
I1023 21:58:10.705917 37954 net.cpp:156] Memory required for data: 864383204
I1023 21:58:10.705921 37954 layer_factory.hpp:77] Creating layer loss_p1
I1023 21:58:10.705930 37954 net.cpp:91] Creating Layer loss_p1
I1023 21:58:10.705935 37954 net.cpp:425] loss_p1 <- fc7_n
I1023 21:58:10.705940 37954 net.cpp:425] loss_p1 <- fc7_pn
I1023 21:58:10.705945 37954 net.cpp:399] loss_p1 -> loss_p1
I1023 21:58:10.705991 37954 net.cpp:141] Setting up loss_p1
I1023 21:58:10.705999 37954 net.cpp:148] Top shape: (1)
I1023 21:58:10.706002 37954 net.cpp:151]     with loss weight -0.35
I1023 21:58:10.706019 37954 net.cpp:156] Memory required for data: 864383208
I1023 21:58:10.706022 37954 layer_factory.hpp:77] Creating layer loss_p2
I1023 21:58:10.706030 37954 net.cpp:91] Creating Layer loss_p2
I1023 21:58:10.706033 37954 net.cpp:425] loss_p2 <- fc8_p_fc8_p_0_split_1
I1023 21:58:10.706038 37954 net.cpp:425] loss_p2 <- label_data_1_split_1
I1023 21:58:10.706043 37954 net.cpp:399] loss_p2 -> loss_p2
I1023 21:58:10.706051 37954 layer_factory.hpp:77] Creating layer loss_p2
I1023 21:58:10.706383 37954 net.cpp:141] Setting up loss_p2
I1023 21:58:10.706394 37954 net.cpp:148] Top shape: (1)
I1023 21:58:10.706398 37954 net.cpp:151]     with loss weight 0.65
I1023 21:58:10.706403 37954 net.cpp:156] Memory required for data: 864383212
I1023 21:58:10.706406 37954 net.cpp:217] loss_p2 needs backward computation.
I1023 21:58:10.706410 37954 net.cpp:217] loss_p1 needs backward computation.
I1023 21:58:10.706413 37954 net.cpp:217] fc7_pn needs backward computation.
I1023 21:58:10.706416 37954 net.cpp:219] accuracy does not need backward computation.
I1023 21:58:10.706420 37954 net.cpp:217] fc8_p_fc8_p_0_split needs backward computation.
I1023 21:58:10.706423 37954 net.cpp:217] fc8_p needs backward computation.
I1023 21:58:10.706426 37954 net.cpp:217] fc7_p_drop7_p_0_split needs backward computation.
I1023 21:58:10.706429 37954 net.cpp:217] drop7_p needs backward computation.
I1023 21:58:10.706432 37954 net.cpp:217] relu7_p needs backward computation.
I1023 21:58:10.706434 37954 net.cpp:217] fc7_p needs backward computation.
I1023 21:58:10.706437 37954 net.cpp:217] drop6_p needs backward computation.
I1023 21:58:10.706440 37954 net.cpp:217] relu6_p needs backward computation.
I1023 21:58:10.706455 37954 net.cpp:217] fc6_p needs backward computation.
I1023 21:58:10.706459 37954 net.cpp:217] pool5_p needs backward computation.
I1023 21:58:10.706462 37954 net.cpp:217] relu5_p needs backward computation.
I1023 21:58:10.706465 37954 net.cpp:217] conv5_p needs backward computation.
I1023 21:58:10.706468 37954 net.cpp:217] relu4_p needs backward computation.
I1023 21:58:10.706471 37954 net.cpp:217] conv4_p needs backward computation.
I1023 21:58:10.706475 37954 net.cpp:217] relu3_p needs backward computation.
I1023 21:58:10.706476 37954 net.cpp:217] conv3_p needs backward computation.
I1023 21:58:10.706480 37954 net.cpp:217] pool2_p needs backward computation.
I1023 21:58:10.706482 37954 net.cpp:217] norm2_p needs backward computation.
I1023 21:58:10.706485 37954 net.cpp:217] relu2_p needs backward computation.
I1023 21:58:10.706488 37954 net.cpp:217] conv2_p needs backward computation.
I1023 21:58:10.706491 37954 net.cpp:217] pool1_p needs backward computation.
I1023 21:58:10.706495 37954 net.cpp:217] norm1_p needs backward computation.
I1023 21:58:10.706497 37954 net.cpp:217] relu1_p needs backward computation.
I1023 21:58:10.706501 37954 net.cpp:217] conv1_p needs backward computation.
I1023 21:58:10.706503 37954 net.cpp:219] fc7_n does not need backward computation.
I1023 21:58:10.706506 37954 net.cpp:219] fc7 does not need backward computation.
I1023 21:58:10.706509 37954 net.cpp:219] drop6 does not need backward computation.
I1023 21:58:10.706512 37954 net.cpp:219] relu6 does not need backward computation.
I1023 21:58:10.706516 37954 net.cpp:219] fc6 does not need backward computation.
I1023 21:58:10.706518 37954 net.cpp:219] pool5 does not need backward computation.
I1023 21:58:10.706521 37954 net.cpp:219] relu5 does not need backward computation.
I1023 21:58:10.706524 37954 net.cpp:219] conv5 does not need backward computation.
I1023 21:58:10.706527 37954 net.cpp:219] relu4 does not need backward computation.
I1023 21:58:10.706531 37954 net.cpp:219] conv4 does not need backward computation.
I1023 21:58:10.706533 37954 net.cpp:219] relu3 does not need backward computation.
I1023 21:58:10.706537 37954 net.cpp:219] conv3 does not need backward computation.
I1023 21:58:10.706539 37954 net.cpp:219] pool2 does not need backward computation.
I1023 21:58:10.706542 37954 net.cpp:219] norm2 does not need backward computation.
I1023 21:58:10.706545 37954 net.cpp:219] relu2 does not need backward computation.
I1023 21:58:10.706548 37954 net.cpp:219] conv2 does not need backward computation.
I1023 21:58:10.706552 37954 net.cpp:219] pool1 does not need backward computation.
I1023 21:58:10.706554 37954 net.cpp:219] norm1 does not need backward computation.
I1023 21:58:10.706560 37954 net.cpp:219] relu1 does not need backward computation.
I1023 21:58:10.706563 37954 net.cpp:219] conv1 does not need backward computation.
I1023 21:58:10.706568 37954 net.cpp:219] label_data_1_split does not need backward computation.
I1023 21:58:10.706571 37954 net.cpp:219] data_data_0_split does not need backward computation.
I1023 21:58:10.706575 37954 net.cpp:219] data does not need backward computation.
I1023 21:58:10.706578 37954 net.cpp:261] This network produces output accuracy
I1023 21:58:10.706580 37954 net.cpp:261] This network produces output loss_p1
I1023 21:58:10.706583 37954 net.cpp:261] This network produces output loss_p2
I1023 21:58:10.706614 37954 net.cpp:274] Network initialization done.
I1023 21:58:10.706800 37954 solver.cpp:60] Solver scaffolding done.
I1023 21:58:10.708052 37954 caffe.cpp:129] Finetuning from models/dissimilarity_siamese_net/pretrained_model/bvlc_alexnet.caffemodel
I1023 21:58:11.224598 37954 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: models/dissimilarity_siamese_net/pretrained_model/bvlc_alexnet.caffemodel
I1023 21:58:11.224635 37954 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W1023 21:58:11.224642 37954 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1023 21:58:11.238373 37954 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: models/dissimilarity_siamese_net/pretrained_model/bvlc_alexnet.caffemodel
I1023 21:58:11.632030 37954 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I1023 21:58:11.674141 37954 net.cpp:752] Ignoring source layer relu7
I1023 21:58:11.674175 37954 net.cpp:752] Ignoring source layer drop7
I1023 21:58:11.674191 37954 net.cpp:752] Ignoring source layer fc8
I1023 21:58:11.674195 37954 net.cpp:752] Ignoring source layer loss
I1023 21:58:12.185936 37954 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: models/dissimilarity_siamese_net/pretrained_model/bvlc_alexnet.caffemodel
I1023 21:58:12.185966 37954 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W1023 21:58:12.185969 37954 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1023 21:58:12.185997 37954 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: models/dissimilarity_siamese_net/pretrained_model/bvlc_alexnet.caffemodel
I1023 21:58:12.576148 37954 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I1023 21:58:12.618306 37954 net.cpp:752] Ignoring source layer relu7
I1023 21:58:12.618350 37954 net.cpp:752] Ignoring source layer drop7
I1023 21:58:12.618355 37954 net.cpp:752] Ignoring source layer fc8
I1023 21:58:12.618356 37954 net.cpp:752] Ignoring source layer loss
I1023 21:58:12.620793 37954 caffe.cpp:219] Starting Optimization
I1023 21:58:12.620872 37954 solver.cpp:279] Solving AlexNet
I1023 21:58:12.620878 37954 solver.cpp:280] Learning Rate Policy: step
I1023 21:58:12.623833 37954 solver.cpp:337] Iteration 0, Testing net (#0)
I1023 22:00:06.564535 37954 solver.cpp:404]     Test net output #0: accuracy = 0.00244
I1023 22:00:06.564657 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.5698 (* -0.35 = -0.549431 loss)
I1023 22:00:06.564666 37954 solver.cpp:404]     Test net output #2: loss_p2 = 6.22535 (* 0.65 = 4.04648 loss)
I1023 22:00:07.129557 37954 solver.cpp:228] Iteration 0, loss = 3.5761
I1023 22:00:07.129602 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.34441 (* -0.35 = -0.470544 loss)
I1023 22:00:07.129619 37954 solver.cpp:244]     Train net output #1: loss_p2 = 6.22561 (* 0.65 = 4.04665 loss)
I1023 22:00:07.129659 37954 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1023 22:00:56.156003 37954 solver.cpp:228] Iteration 40, loss = 3.53406
I1023 22:00:56.156241 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.40751 (* -0.35 = -0.492627 loss)
I1023 22:00:56.156251 37954 solver.cpp:244]     Train net output #1: loss_p2 = 6.1949 (* 0.65 = 4.02669 loss)
I1023 22:00:56.156260 37954 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I1023 22:01:45.231863 37954 solver.cpp:228] Iteration 80, loss = 3.53231
I1023 22:01:45.232096 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.41532 (* -0.35 = -0.495361 loss)
I1023 22:01:45.232105 37954 solver.cpp:244]     Train net output #1: loss_p2 = 6.19642 (* 0.65 = 4.02767 loss)
I1023 22:01:45.232115 37954 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I1023 22:02:34.289528 37954 solver.cpp:228] Iteration 120, loss = 3.5302
I1023 22:02:34.289765 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.42238 (* -0.35 = -0.497834 loss)
I1023 22:02:34.289775 37954 solver.cpp:244]     Train net output #1: loss_p2 = 6.19697 (* 0.65 = 4.02803 loss)
I1023 22:02:34.289784 37954 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I1023 22:03:23.267014 37954 solver.cpp:228] Iteration 160, loss = 3.5089
I1023 22:03:23.267267 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.42521 (* -0.35 = -0.498825 loss)
I1023 22:03:23.267278 37954 solver.cpp:244]     Train net output #1: loss_p2 = 6.16572 (* 0.65 = 4.00772 loss)
I1023 22:03:23.267287 37954 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I1023 22:04:12.292040 37954 solver.cpp:228] Iteration 200, loss = 3.50119
I1023 22:04:12.292269 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.4258 (* -0.35 = -0.499029 loss)
I1023 22:04:12.292280 37954 solver.cpp:244]     Train net output #1: loss_p2 = 6.15418 (* 0.65 = 4.00022 loss)
I1023 22:04:12.292289 37954 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I1023 22:05:01.258931 37954 solver.cpp:228] Iteration 240, loss = 3.50053
I1023 22:05:01.259155 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.427 (* -0.35 = -0.49945 loss)
I1023 22:05:01.259163 37954 solver.cpp:244]     Train net output #1: loss_p2 = 6.15381 (* 0.65 = 3.99998 loss)
I1023 22:05:01.259172 37954 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I1023 22:05:50.251893 37954 solver.cpp:228] Iteration 280, loss = 3.49485
I1023 22:05:50.252096 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.41254 (* -0.35 = -0.494389 loss)
I1023 22:05:50.252113 37954 solver.cpp:244]     Train net output #1: loss_p2 = 6.13729 (* 0.65 = 3.98924 loss)
I1023 22:05:50.252120 37954 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I1023 22:06:39.329576 37954 solver.cpp:228] Iteration 320, loss = 3.47682
I1023 22:06:39.329819 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.39045 (* -0.35 = -0.486658 loss)
I1023 22:06:39.329829 37954 solver.cpp:244]     Train net output #1: loss_p2 = 6.09767 (* 0.65 = 3.96348 loss)
I1023 22:06:39.329838 37954 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I1023 22:07:28.439584 37954 solver.cpp:228] Iteration 360, loss = 3.4569
I1023 22:07:28.439821 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.38021 (* -0.35 = -0.483073 loss)
I1023 22:07:28.439831 37954 solver.cpp:244]     Train net output #1: loss_p2 = 6.06149 (* 0.65 = 3.93997 loss)
I1023 22:07:28.439839 37954 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I1023 22:08:17.560328 37954 solver.cpp:228] Iteration 400, loss = 3.39619
I1023 22:08:17.560564 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.36634 (* -0.35 = -0.47822 loss)
I1023 22:08:17.560573 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.96063 (* 0.65 = 3.87441 loss)
I1023 22:08:17.560580 37954 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I1023 22:09:06.661350 37954 solver.cpp:228] Iteration 440, loss = 3.39738
I1023 22:09:06.661556 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.36501 (* -0.35 = -0.477752 loss)
I1023 22:09:06.661574 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.96173 (* 0.65 = 3.87513 loss)
I1023 22:09:06.661582 37954 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I1023 22:09:55.765539 37954 solver.cpp:228] Iteration 480, loss = 3.3484
I1023 22:09:55.765782 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35977 (* -0.35 = -0.475921 loss)
I1023 22:09:55.765792 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.88357 (* 0.65 = 3.82432 loss)
I1023 22:09:55.765801 37954 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I1023 22:10:19.091960 37954 solver.cpp:337] Iteration 500, Testing net (#0)
I1023 22:12:13.388002 37954 solver.cpp:404]     Test net output #0: accuracy = 0.00731999
I1023 22:12:13.388231 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.56631 (* -0.35 = -0.54821 loss)
I1023 22:12:13.388240 37954 solver.cpp:404]     Test net output #2: loss_p2 = 5.99386 (* 0.65 = 3.89601 loss)
I1023 22:12:38.490370 37954 solver.cpp:228] Iteration 520, loss = 3.35146
I1023 22:12:38.490427 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.36976 (* -0.35 = -0.479418 loss)
I1023 22:12:38.490434 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.89365 (* 0.65 = 3.83087 loss)
I1023 22:12:38.490442 37954 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I1023 22:13:27.606708 37954 solver.cpp:228] Iteration 560, loss = 3.33718
I1023 22:13:27.606966 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.36063 (* -0.35 = -0.47622 loss)
I1023 22:13:27.606976 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.86678 (* 0.65 = 3.8134 loss)
I1023 22:13:27.606984 37954 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I1023 22:14:16.684869 37954 solver.cpp:228] Iteration 600, loss = 3.33835
I1023 22:14:16.685082 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.36632 (* -0.35 = -0.478213 loss)
I1023 22:14:16.685101 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.87163 (* 0.65 = 3.81656 loss)
I1023 22:14:16.685109 37954 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I1023 22:15:05.762886 37954 solver.cpp:228] Iteration 640, loss = 3.3615
I1023 22:15:05.763106 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.37367 (* -0.35 = -0.480783 loss)
I1023 22:15:05.763116 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.9112 (* 0.65 = 3.84228 loss)
I1023 22:15:05.763125 37954 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I1023 22:15:54.849557 37954 solver.cpp:228] Iteration 680, loss = 3.33032
I1023 22:15:54.849812 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.36738 (* -0.35 = -0.478584 loss)
I1023 22:15:54.849822 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.85985 (* 0.65 = 3.80891 loss)
I1023 22:15:54.849831 37954 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I1023 22:16:43.932324 37954 solver.cpp:228] Iteration 720, loss = 3.23198
I1023 22:16:43.932540 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35784 (* -0.35 = -0.475243 loss)
I1023 22:16:43.932549 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.70342 (* 0.65 = 3.70723 loss)
I1023 22:16:43.932559 37954 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I1023 22:17:33.029467 37954 solver.cpp:228] Iteration 760, loss = 3.22352
I1023 22:17:33.029697 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.37019 (* -0.35 = -0.479566 loss)
I1023 22:17:33.029706 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.69706 (* 0.65 = 3.70309 loss)
I1023 22:17:33.029716 37954 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I1023 22:18:22.101256 37954 solver.cpp:228] Iteration 800, loss = 3.17905
I1023 22:18:22.101483 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35827 (* -0.35 = -0.475396 loss)
I1023 22:18:22.101492 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.62222 (* 0.65 = 3.65444 loss)
I1023 22:18:22.101501 37954 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I1023 22:19:11.192461 37954 solver.cpp:228] Iteration 840, loss = 3.24042
I1023 22:19:11.192698 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.36442 (* -0.35 = -0.477548 loss)
I1023 22:19:11.192708 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.71995 (* 0.65 = 3.71797 loss)
I1023 22:19:11.192718 37954 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I1023 22:19:59.941917 37954 solver.cpp:228] Iteration 880, loss = 3.17828
I1023 22:19:59.942095 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.3657 (* -0.35 = -0.477995 loss)
I1023 22:19:59.942114 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.62504 (* 0.65 = 3.65627 loss)
I1023 22:19:59.942121 37954 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I1023 22:20:48.546092 37954 solver.cpp:228] Iteration 920, loss = 3.17559
I1023 22:20:48.546226 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35961 (* -0.35 = -0.475864 loss)
I1023 22:20:48.546236 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.61762 (* 0.65 = 3.65145 loss)
I1023 22:20:48.546241 37954 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I1023 22:21:37.147017 37954 solver.cpp:228] Iteration 960, loss = 3.14214
I1023 22:21:37.147171 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.36878 (* -0.35 = -0.479072 loss)
I1023 22:21:37.147181 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.5711 (* 0.65 = 3.62121 loss)
I1023 22:21:37.147186 37954 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I1023 22:22:24.524384 37954 solver.cpp:454] Snapshotting to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_1000.caffemodel
I1023 22:22:29.917235 37954 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_1000.solverstate
I1023 22:22:32.716521 37954 solver.cpp:337] Iteration 1000, Testing net (#0)
I1023 22:24:26.259207 37954 solver.cpp:404]     Test net output #0: accuracy = 0.0189801
I1023 22:24:26.259413 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.55711 (* -0.35 = -0.544989 loss)
I1023 22:24:26.259421 37954 solver.cpp:404]     Test net output #2: loss_p2 = 5.71222 (* 0.65 = 3.71294 loss)
I1023 22:24:26.788030 37954 solver.cpp:228] Iteration 1000, loss = 3.16518
I1023 22:24:26.788058 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35295 (* -0.35 = -0.473534 loss)
I1023 22:24:26.788065 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.59803 (* 0.65 = 3.63872 loss)
I1023 22:24:26.788074 37954 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I1023 22:25:15.400936 37954 solver.cpp:228] Iteration 1040, loss = 3.2296
I1023 22:25:15.401098 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35996 (* -0.35 = -0.475985 loss)
I1023 22:25:15.401106 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.7009 (* 0.65 = 3.70559 loss)
I1023 22:25:15.401113 37954 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I1023 22:26:04.016819 37954 solver.cpp:228] Iteration 1080, loss = 3.08965
I1023 22:26:04.016963 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.36344 (* -0.35 = -0.477206 loss)
I1023 22:26:04.016971 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.48747 (* 0.65 = 3.56686 loss)
I1023 22:26:04.016978 37954 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I1023 22:26:52.648370 37954 solver.cpp:228] Iteration 1120, loss = 3.10364
I1023 22:26:52.648586 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35648 (* -0.35 = -0.474767 loss)
I1023 22:26:52.648597 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.50524 (* 0.65 = 3.57841 loss)
I1023 22:26:52.648602 37954 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I1023 22:27:41.253701 37954 solver.cpp:228] Iteration 1160, loss = 3.0521
I1023 22:27:41.253834 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.36031 (* -0.35 = -0.47611 loss)
I1023 22:27:41.253842 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.42802 (* 0.65 = 3.52821 loss)
I1023 22:27:41.253849 37954 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I1023 22:28:29.864480 37954 solver.cpp:228] Iteration 1200, loss = 3.05815
I1023 22:28:29.864650 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35622 (* -0.35 = -0.474678 loss)
I1023 22:28:29.864663 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.43513 (* 0.65 = 3.53283 loss)
I1023 22:28:29.864670 37954 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I1023 22:29:18.465838 37954 solver.cpp:228] Iteration 1240, loss = 3.09645
I1023 22:29:18.465994 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.3609 (* -0.35 = -0.476316 loss)
I1023 22:29:18.466003 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.49657 (* 0.65 = 3.57277 loss)
I1023 22:29:18.466009 37954 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I1023 22:30:07.166177 37954 solver.cpp:228] Iteration 1280, loss = 3.03849
I1023 22:30:07.166462 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35827 (* -0.35 = -0.475394 loss)
I1023 22:30:07.166472 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.40598 (* 0.65 = 3.51389 loss)
I1023 22:30:07.166481 37954 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I1023 22:30:56.198665 37954 solver.cpp:228] Iteration 1320, loss = 3.10029
I1023 22:30:56.198947 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35424 (* -0.35 = -0.473985 loss)
I1023 22:30:56.198957 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.49888 (* 0.65 = 3.57427 loss)
I1023 22:30:56.198966 37954 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I1023 22:31:45.221288 37954 solver.cpp:228] Iteration 1360, loss = 2.98022
I1023 22:31:45.221601 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35602 (* -0.35 = -0.474608 loss)
I1023 22:31:45.221611 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.31512 (* 0.65 = 3.45483 loss)
I1023 22:31:45.221619 37954 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I1023 22:32:34.250974 37954 solver.cpp:228] Iteration 1400, loss = 3.05861
I1023 22:32:34.251258 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35475 (* -0.35 = -0.474164 loss)
I1023 22:32:34.251268 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.43504 (* 0.65 = 3.53277 loss)
I1023 22:32:34.251277 37954 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I1023 22:33:23.306263 37954 solver.cpp:228] Iteration 1440, loss = 2.93795
I1023 22:33:23.306538 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35031 (* -0.35 = -0.472608 loss)
I1023 22:33:23.306548 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.24701 (* 0.65 = 3.41055 loss)
I1023 22:33:23.306557 37954 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I1023 22:34:12.356111 37954 solver.cpp:228] Iteration 1480, loss = 3.02515
I1023 22:34:12.356384 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35399 (* -0.35 = -0.473898 loss)
I1023 22:34:12.356393 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.38315 (* 0.65 = 3.49905 loss)
I1023 22:34:12.356402 37954 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I1023 22:34:35.652783 37954 solver.cpp:337] Iteration 1500, Testing net (#0)
I1023 22:36:29.913502 37954 solver.cpp:404]     Test net output #0: accuracy = 0.0390403
I1023 22:36:29.913698 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.54556 (* -0.35 = -0.540947 loss)
I1023 22:36:29.913707 37954 solver.cpp:404]     Test net output #2: loss_p2 = 5.38424 (* 0.65 = 3.49975 loss)
I1023 22:36:54.982853 37954 solver.cpp:228] Iteration 1520, loss = 2.98753
I1023 22:36:54.982928 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35658 (* -0.35 = -0.474804 loss)
I1023 22:36:54.982938 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.32667 (* 0.65 = 3.46233 loss)
I1023 22:36:54.982947 37954 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I1023 22:37:44.025831 37954 solver.cpp:228] Iteration 1560, loss = 2.8827
I1023 22:37:44.026109 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35521 (* -0.35 = -0.474323 loss)
I1023 22:37:44.026119 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.16464 (* 0.65 = 3.35702 loss)
I1023 22:37:44.026129 37954 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I1023 22:38:32.874775 37954 solver.cpp:228] Iteration 1600, loss = 2.94833
I1023 22:38:32.875020 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35251 (* -0.35 = -0.473377 loss)
I1023 22:38:32.875030 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.26417 (* 0.65 = 3.42171 loss)
I1023 22:38:32.875036 37954 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I1023 22:39:21.539155 37954 solver.cpp:228] Iteration 1640, loss = 2.99745
I1023 22:39:21.539327 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35225 (* -0.35 = -0.473289 loss)
I1023 22:39:21.539337 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.33959 (* 0.65 = 3.47073 loss)
I1023 22:39:21.539343 37954 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I1023 22:40:10.205237 37954 solver.cpp:228] Iteration 1680, loss = 2.88687
I1023 22:40:10.205405 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.34967 (* -0.35 = -0.472385 loss)
I1023 22:40:10.205415 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.16808 (* 0.65 = 3.35925 loss)
I1023 22:40:10.205420 37954 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I1023 22:40:58.864789 37954 solver.cpp:228] Iteration 1720, loss = 2.95819
I1023 22:40:58.864958 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35156 (* -0.35 = -0.473047 loss)
I1023 22:40:58.864966 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.27882 (* 0.65 = 3.43124 loss)
I1023 22:40:58.864972 37954 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I1023 22:41:47.540379 37954 solver.cpp:228] Iteration 1760, loss = 2.82483
I1023 22:41:47.540572 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35209 (* -0.35 = -0.473231 loss)
I1023 22:41:47.540581 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.07394 (* 0.65 = 3.29806 loss)
I1023 22:41:47.540587 37954 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I1023 22:42:36.199887 37954 solver.cpp:228] Iteration 1800, loss = 2.82272
I1023 22:42:36.200055 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.35098 (* -0.35 = -0.472843 loss)
I1023 22:42:36.200064 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.0701 (* 0.65 = 3.29556 loss)
I1023 22:42:36.200070 37954 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I1023 22:43:24.875818 37954 solver.cpp:228] Iteration 1840, loss = 2.8696
I1023 22:43:24.875984 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.34412 (* -0.35 = -0.470443 loss)
I1023 22:43:24.875993 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.13853 (* 0.65 = 3.34004 loss)
I1023 22:43:24.875999 37954 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I1023 22:44:13.566294 37954 solver.cpp:228] Iteration 1880, loss = 2.86645
I1023 22:44:13.566463 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.34607 (* -0.35 = -0.471126 loss)
I1023 22:44:13.566473 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.13473 (* 0.65 = 3.33757 loss)
I1023 22:44:13.566478 37954 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I1023 22:45:02.231595 37954 solver.cpp:228] Iteration 1920, loss = 2.81436
I1023 22:45:02.231760 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.34555 (* -0.35 = -0.470942 loss)
I1023 22:45:02.231770 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.05431 (* 0.65 = 3.2853 loss)
I1023 22:45:02.231775 37954 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I1023 22:45:50.896913 37954 solver.cpp:228] Iteration 1960, loss = 2.80345
I1023 22:45:50.897083 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.3451 (* -0.35 = -0.470785 loss)
I1023 22:45:50.897094 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.03728 (* 0.65 = 3.27423 loss)
I1023 22:45:50.897099 37954 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I1023 22:46:38.337380 37954 solver.cpp:454] Snapshotting to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_2000.caffemodel
I1023 22:46:43.558838 37954 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_2000.solverstate
I1023 22:46:46.322847 37954 solver.cpp:337] Iteration 2000, Testing net (#0)
I1023 22:48:39.934414 37954 solver.cpp:404]     Test net output #0: accuracy = 0.0550004
I1023 22:48:39.934609 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.53611 (* -0.35 = -0.537639 loss)
I1023 22:48:39.934619 37954 solver.cpp:404]     Test net output #2: loss_p2 = 5.16467 (* 0.65 = 3.35704 loss)
I1023 22:48:40.476625 37954 solver.cpp:228] Iteration 2000, loss = 2.91197
I1023 22:48:40.476676 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33592 (* -0.35 = -0.467571 loss)
I1023 22:48:40.476685 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.19929 (* 0.65 = 3.37954 loss)
I1023 22:48:40.476692 37954 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I1023 22:49:29.171049 37954 solver.cpp:228] Iteration 2040, loss = 2.7865
I1023 22:49:29.171308 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.34468 (* -0.35 = -0.470638 loss)
I1023 22:49:29.171316 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.01099 (* 0.65 = 3.25714 loss)
I1023 22:49:29.171322 37954 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I1023 22:50:17.837455 37954 solver.cpp:228] Iteration 2080, loss = 2.83776
I1023 22:50:17.837620 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.34244 (* -0.35 = -0.469854 loss)
I1023 22:50:17.837630 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.08863 (* 0.65 = 3.30761 loss)
I1023 22:50:17.837636 37954 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I1023 22:51:06.503593 37954 solver.cpp:228] Iteration 2120, loss = 2.88673
I1023 22:51:06.503743 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.34504 (* -0.35 = -0.470765 loss)
I1023 22:51:06.503753 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.16537 (* 0.65 = 3.35749 loss)
I1023 22:51:06.503759 37954 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I1023 22:51:55.175545 37954 solver.cpp:228] Iteration 2160, loss = 2.83434
I1023 22:51:55.175690 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33758 (* -0.35 = -0.468151 loss)
I1023 22:51:55.175700 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.08076 (* 0.65 = 3.30249 loss)
I1023 22:51:55.175706 37954 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I1023 22:52:43.844885 37954 solver.cpp:228] Iteration 2200, loss = 2.77318
I1023 22:52:43.845049 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33853 (* -0.35 = -0.468485 loss)
I1023 22:52:43.845058 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.98718 (* 0.65 = 3.24167 loss)
I1023 22:52:43.845064 37954 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I1023 22:53:32.496160 37954 solver.cpp:228] Iteration 2240, loss = 2.86458
I1023 22:53:32.496292 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33597 (* -0.35 = -0.467588 loss)
I1023 22:53:32.496301 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.12641 (* 0.65 = 3.33217 loss)
I1023 22:53:32.496307 37954 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I1023 22:54:21.186754 37954 solver.cpp:228] Iteration 2280, loss = 2.7803
I1023 22:54:21.186918 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33866 (* -0.35 = -0.468532 loss)
I1023 22:54:21.186928 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.9982 (* 0.65 = 3.24883 loss)
I1023 22:54:21.186933 37954 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I1023 22:55:09.853446 37954 solver.cpp:228] Iteration 2320, loss = 2.91124
I1023 22:55:09.853588 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.34066 (* -0.35 = -0.46923 loss)
I1023 22:55:09.853597 37954 solver.cpp:244]     Train net output #1: loss_p2 = 5.20072 (* 0.65 = 3.38047 loss)
I1023 22:55:09.853603 37954 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I1023 22:55:58.517943 37954 solver.cpp:228] Iteration 2360, loss = 2.67913
I1023 22:55:58.518110 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33615 (* -0.35 = -0.467651 loss)
I1023 22:55:58.518120 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.8412 (* 0.65 = 3.14678 loss)
I1023 22:55:58.518126 37954 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I1023 22:56:47.177027 37954 solver.cpp:228] Iteration 2400, loss = 2.74874
I1023 22:56:47.177197 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33852 (* -0.35 = -0.468483 loss)
I1023 22:56:47.177206 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.94957 (* 0.65 = 3.21722 loss)
I1023 22:56:47.177212 37954 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I1023 22:57:35.821877 37954 solver.cpp:228] Iteration 2440, loss = 2.67322
I1023 22:57:35.822047 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33836 (* -0.35 = -0.468427 loss)
I1023 22:57:35.822057 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.8333 (* 0.65 = 3.14164 loss)
I1023 22:57:35.822062 37954 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I1023 22:58:24.494832 37954 solver.cpp:228] Iteration 2480, loss = 2.64604
I1023 22:58:24.495012 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33742 (* -0.35 = -0.468097 loss)
I1023 22:58:24.495020 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.79098 (* 0.65 = 3.11414 loss)
I1023 22:58:24.495026 37954 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I1023 22:58:47.616919 37954 solver.cpp:337] Iteration 2500, Testing net (#0)
I1023 23:00:41.884469 37954 solver.cpp:404]     Test net output #0: accuracy = 0.0756602
I1023 23:00:41.884759 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.52574 (* -0.35 = -0.534009 loss)
I1023 23:00:41.884769 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.96813 (* 0.65 = 3.22929 loss)
I1023 23:01:06.762475 37954 solver.cpp:228] Iteration 2520, loss = 2.60911
I1023 23:01:06.762506 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33471 (* -0.35 = -0.46715 loss)
I1023 23:01:06.762513 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.7327 (* 0.65 = 3.07626 loss)
I1023 23:01:06.762518 37954 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I1023 23:01:55.418818 37954 solver.cpp:228] Iteration 2560, loss = 2.59843
I1023 23:01:55.418977 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33034 (* -0.35 = -0.465618 loss)
I1023 23:01:55.418985 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.71392 (* 0.65 = 3.06405 loss)
I1023 23:01:55.418992 37954 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I1023 23:02:44.081328 37954 solver.cpp:228] Iteration 2600, loss = 2.69374
I1023 23:02:44.081508 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33419 (* -0.35 = -0.466966 loss)
I1023 23:02:44.081518 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.86263 (* 0.65 = 3.16071 loss)
I1023 23:02:44.081524 37954 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I1023 23:03:32.738286 37954 solver.cpp:228] Iteration 2640, loss = 2.71061
I1023 23:03:32.738454 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.32723 (* -0.35 = -0.464532 loss)
I1023 23:03:32.738463 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.88483 (* 0.65 = 3.17514 loss)
I1023 23:03:32.738469 37954 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I1023 23:04:21.415664 37954 solver.cpp:228] Iteration 2680, loss = 2.62285
I1023 23:04:21.415832 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33142 (* -0.35 = -0.465998 loss)
I1023 23:04:21.415843 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.75208 (* 0.65 = 3.08885 loss)
I1023 23:04:21.415848 37954 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I1023 23:05:10.063799 37954 solver.cpp:228] Iteration 2720, loss = 2.59927
I1023 23:05:10.063966 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.32614 (* -0.35 = -0.464148 loss)
I1023 23:05:10.063977 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.71295 (* 0.65 = 3.06341 loss)
I1023 23:05:10.063982 37954 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I1023 23:05:58.755802 37954 solver.cpp:228] Iteration 2760, loss = 2.62634
I1023 23:05:58.755976 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33093 (* -0.35 = -0.465825 loss)
I1023 23:05:58.755986 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.75718 (* 0.65 = 3.09216 loss)
I1023 23:05:58.755991 37954 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I1023 23:06:47.429401 37954 solver.cpp:228] Iteration 2800, loss = 2.74709
I1023 23:06:47.429571 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.32776 (* -0.35 = -0.464715 loss)
I1023 23:06:47.429580 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.94124 (* 0.65 = 3.21181 loss)
I1023 23:06:47.429586 37954 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I1023 23:07:36.087555 37954 solver.cpp:228] Iteration 2840, loss = 2.67453
I1023 23:07:36.087724 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.33386 (* -0.35 = -0.466851 loss)
I1023 23:07:36.087734 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.8329 (* 0.65 = 3.14138 loss)
I1023 23:07:36.087739 37954 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I1023 23:08:24.758070 37954 solver.cpp:228] Iteration 2880, loss = 2.47145
I1023 23:08:24.758247 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.3224 (* -0.35 = -0.462842 loss)
I1023 23:08:24.758257 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.5143 (* 0.65 = 2.9343 loss)
I1023 23:08:24.758263 37954 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I1023 23:09:13.420677 37954 solver.cpp:228] Iteration 2920, loss = 2.54827
I1023 23:09:13.420848 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.32485 (* -0.35 = -0.463697 loss)
I1023 23:09:13.420858 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.6338 (* 0.65 = 3.01197 loss)
I1023 23:09:13.420864 37954 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I1023 23:10:02.055701 37954 solver.cpp:228] Iteration 2960, loss = 2.66128
I1023 23:10:02.055882 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.32597 (* -0.35 = -0.464089 loss)
I1023 23:10:02.055891 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.80826 (* 0.65 = 3.12537 loss)
I1023 23:10:02.055897 37954 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I1023 23:10:49.507586 37954 solver.cpp:454] Snapshotting to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_3000.caffemodel
I1023 23:10:54.701530 37954 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_3000.solverstate
I1023 23:10:57.486397 37954 solver.cpp:337] Iteration 3000, Testing net (#0)
I1023 23:12:51.185286 37954 solver.cpp:404]     Test net output #0: accuracy = 0.0838001
I1023 23:12:51.185549 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.50686 (* -0.35 = -0.527401 loss)
I1023 23:12:51.185557 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.88206 (* 0.65 = 3.17334 loss)
I1023 23:12:51.716186 37954 solver.cpp:228] Iteration 3000, loss = 2.50126
I1023 23:12:51.716214 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.32524 (* -0.35 = -0.463835 loss)
I1023 23:12:51.716223 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.56169 (* 0.65 = 2.9651 loss)
I1023 23:12:51.716230 37954 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I1023 23:13:40.379686 37954 solver.cpp:228] Iteration 3040, loss = 2.45802
I1023 23:13:40.379858 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.32146 (* -0.35 = -0.46251 loss)
I1023 23:13:40.379868 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.49312 (* 0.65 = 2.92053 loss)
I1023 23:13:40.379873 37954 sgd_solver.cpp:106] Iteration 3040, lr = 0.01
I1023 23:14:29.017532 37954 solver.cpp:228] Iteration 3080, loss = 2.53196
I1023 23:14:29.017700 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.32342 (* -0.35 = -0.463197 loss)
I1023 23:14:29.017710 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.60793 (* 0.65 = 2.99516 loss)
I1023 23:14:29.017716 37954 sgd_solver.cpp:106] Iteration 3080, lr = 0.01
I1023 23:15:17.676839 37954 solver.cpp:228] Iteration 3120, loss = 2.59522
I1023 23:15:17.677006 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.32136 (* -0.35 = -0.462477 loss)
I1023 23:15:17.677014 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.70415 (* 0.65 = 3.0577 loss)
I1023 23:15:17.677021 37954 sgd_solver.cpp:106] Iteration 3120, lr = 0.01
I1023 23:16:06.347476 37954 solver.cpp:228] Iteration 3160, loss = 2.43666
I1023 23:16:06.347643 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.32216 (* -0.35 = -0.462755 loss)
I1023 23:16:06.347652 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.46064 (* 0.65 = 2.89942 loss)
I1023 23:16:06.347658 37954 sgd_solver.cpp:106] Iteration 3160, lr = 0.01
I1023 23:16:55.011760 37954 solver.cpp:228] Iteration 3200, loss = 2.68074
I1023 23:16:55.011927 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31537 (* -0.35 = -0.460379 loss)
I1023 23:16:55.011937 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.83249 (* 0.65 = 3.14112 loss)
I1023 23:16:55.011942 37954 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I1023 23:17:43.659142 37954 solver.cpp:228] Iteration 3240, loss = 2.49588
I1023 23:17:43.659312 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31676 (* -0.35 = -0.460867 loss)
I1023 23:17:43.659320 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.54884 (* 0.65 = 2.95675 loss)
I1023 23:17:43.659327 37954 sgd_solver.cpp:106] Iteration 3240, lr = 0.01
I1023 23:18:32.323400 37954 solver.cpp:228] Iteration 3280, loss = 2.32443
I1023 23:18:32.323573 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31584 (* -0.35 = -0.460544 loss)
I1023 23:18:32.323583 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.28458 (* 0.65 = 2.78498 loss)
I1023 23:18:32.323588 37954 sgd_solver.cpp:106] Iteration 3280, lr = 0.01
I1023 23:19:20.982111 37954 solver.cpp:228] Iteration 3320, loss = 2.4411
I1023 23:19:20.982292 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31598 (* -0.35 = -0.460594 loss)
I1023 23:19:20.982302 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.46415 (* 0.65 = 2.9017 loss)
I1023 23:19:20.982308 37954 sgd_solver.cpp:106] Iteration 3320, lr = 0.01
I1023 23:20:09.649704 37954 solver.cpp:228] Iteration 3360, loss = 2.3799
I1023 23:20:09.649837 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31965 (* -0.35 = -0.461876 loss)
I1023 23:20:09.649847 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.37197 (* 0.65 = 2.84178 loss)
I1023 23:20:09.649852 37954 sgd_solver.cpp:106] Iteration 3360, lr = 0.01
I1023 23:20:58.304875 37954 solver.cpp:228] Iteration 3400, loss = 2.32496
I1023 23:20:58.305045 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31683 (* -0.35 = -0.460892 loss)
I1023 23:20:58.305054 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.28593 (* 0.65 = 2.78585 loss)
I1023 23:20:58.305060 37954 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I1023 23:21:46.990430 37954 solver.cpp:228] Iteration 3440, loss = 2.58228
I1023 23:21:46.990597 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31639 (* -0.35 = -0.460735 loss)
I1023 23:21:46.990607 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.68156 (* 0.65 = 3.04301 loss)
I1023 23:21:46.990612 37954 sgd_solver.cpp:106] Iteration 3440, lr = 0.01
I1023 23:22:35.637596 37954 solver.cpp:228] Iteration 3480, loss = 2.5206
I1023 23:22:35.637763 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31251 (* -0.35 = -0.459378 loss)
I1023 23:22:35.637773 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.58458 (* 0.65 = 2.97997 loss)
I1023 23:22:35.637778 37954 sgd_solver.cpp:106] Iteration 3480, lr = 0.01
I1023 23:22:58.741425 37954 solver.cpp:337] Iteration 3500, Testing net (#0)
I1023 23:24:53.148980 37954 solver.cpp:404]     Test net output #0: accuracy = 0.0992401
I1023 23:24:53.149266 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.49039 (* -0.35 = -0.521635 loss)
I1023 23:24:53.149274 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.77596 (* 0.65 = 3.10437 loss)
I1023 23:25:18.013273 37954 solver.cpp:228] Iteration 3520, loss = 2.47988
I1023 23:25:18.013303 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31121 (* -0.35 = -0.458925 loss)
I1023 23:25:18.013311 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.52123 (* 0.65 = 2.9388 loss)
I1023 23:25:18.013316 37954 sgd_solver.cpp:106] Iteration 3520, lr = 0.01
I1023 23:26:06.643692 37954 solver.cpp:228] Iteration 3560, loss = 2.51234
I1023 23:26:06.643859 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31321 (* -0.35 = -0.459624 loss)
I1023 23:26:06.643869 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.57226 (* 0.65 = 2.97197 loss)
I1023 23:26:06.643874 37954 sgd_solver.cpp:106] Iteration 3560, lr = 0.01
I1023 23:26:55.291535 37954 solver.cpp:228] Iteration 3600, loss = 2.45009
I1023 23:26:55.291667 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31257 (* -0.35 = -0.459398 loss)
I1023 23:26:55.291685 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.47614 (* 0.65 = 2.90949 loss)
I1023 23:26:55.291690 37954 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I1023 23:27:43.954943 37954 solver.cpp:228] Iteration 3640, loss = 2.38836
I1023 23:27:43.955112 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31484 (* -0.35 = -0.460193 loss)
I1023 23:27:43.955121 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.38239 (* 0.65 = 2.84855 loss)
I1023 23:27:43.955127 37954 sgd_solver.cpp:106] Iteration 3640, lr = 0.01
I1023 23:28:32.627909 37954 solver.cpp:228] Iteration 3680, loss = 2.41795
I1023 23:28:32.628082 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.31726 (* -0.35 = -0.46104 loss)
I1023 23:28:32.628092 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.42922 (* 0.65 = 2.87899 loss)
I1023 23:28:32.628096 37954 sgd_solver.cpp:106] Iteration 3680, lr = 0.01
I1023 23:29:21.297993 37954 solver.cpp:228] Iteration 3720, loss = 2.29853
I1023 23:29:21.298153 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.30968 (* -0.35 = -0.458388 loss)
I1023 23:29:21.298163 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.24141 (* 0.65 = 2.75692 loss)
I1023 23:29:21.298168 37954 sgd_solver.cpp:106] Iteration 3720, lr = 0.01
I1023 23:30:10.009480 37954 solver.cpp:228] Iteration 3760, loss = 2.52637
I1023 23:30:10.009754 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.30865 (* -0.35 = -0.458027 loss)
I1023 23:30:10.009765 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.59138 (* 0.65 = 2.9844 loss)
I1023 23:30:10.009771 37954 sgd_solver.cpp:106] Iteration 3760, lr = 0.01
I1023 23:30:58.665244 37954 solver.cpp:228] Iteration 3800, loss = 2.32391
I1023 23:30:58.665369 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.30393 (* -0.35 = -0.456376 loss)
I1023 23:30:58.665380 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.27737 (* 0.65 = 2.78029 loss)
I1023 23:30:58.665387 37954 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I1023 23:31:47.344894 37954 solver.cpp:228] Iteration 3840, loss = 2.4357
I1023 23:31:47.345031 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.30584 (* -0.35 = -0.457043 loss)
I1023 23:31:47.345039 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.45038 (* 0.65 = 2.89275 loss)
I1023 23:31:47.345046 37954 sgd_solver.cpp:106] Iteration 3840, lr = 0.01
I1023 23:32:36.008234 37954 solver.cpp:228] Iteration 3880, loss = 2.34743
I1023 23:32:36.008407 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.30468 (* -0.35 = -0.456637 loss)
I1023 23:32:36.008417 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.31395 (* 0.65 = 2.80407 loss)
I1023 23:32:36.008422 37954 sgd_solver.cpp:106] Iteration 3880, lr = 0.01
I1023 23:33:24.664445 37954 solver.cpp:228] Iteration 3920, loss = 2.3339
I1023 23:33:24.664577 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.30985 (* -0.35 = -0.458447 loss)
I1023 23:33:24.664587 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.29592 (* 0.65 = 2.79235 loss)
I1023 23:33:24.664592 37954 sgd_solver.cpp:106] Iteration 3920, lr = 0.01
I1023 23:34:13.327133 37954 solver.cpp:228] Iteration 3960, loss = 2.31501
I1023 23:34:13.327272 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.30768 (* -0.35 = -0.45769 loss)
I1023 23:34:13.327282 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.26569 (* 0.65 = 2.7727 loss)
I1023 23:34:13.327287 37954 sgd_solver.cpp:106] Iteration 3960, lr = 0.01
I1023 23:35:00.796021 37954 solver.cpp:454] Snapshotting to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_4000.caffemodel
I1023 23:35:06.015347 37954 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_4000.solverstate
I1023 23:35:08.801463 37954 solver.cpp:337] Iteration 4000, Testing net (#0)
I1023 23:37:02.624444 37954 solver.cpp:404]     Test net output #0: accuracy = 0.0983002
I1023 23:37:02.624697 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.46229 (* -0.35 = -0.511801 loss)
I1023 23:37:02.624706 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.80738 (* 0.65 = 3.1248 loss)
I1023 23:37:03.157346 37954 solver.cpp:228] Iteration 4000, loss = 2.43544
I1023 23:37:03.157376 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.29729 (* -0.35 = -0.454052 loss)
I1023 23:37:03.157382 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.44537 (* 0.65 = 2.88949 loss)
I1023 23:37:03.157392 37954 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I1023 23:37:51.809223 37954 solver.cpp:228] Iteration 4040, loss = 2.31896
I1023 23:37:51.809389 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.30349 (* -0.35 = -0.456222 loss)
I1023 23:37:51.809399 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.26951 (* 0.65 = 2.77518 loss)
I1023 23:37:51.809404 37954 sgd_solver.cpp:106] Iteration 4040, lr = 0.01
I1023 23:38:40.446081 37954 solver.cpp:228] Iteration 4080, loss = 2.326
I1023 23:38:40.446282 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.30028 (* -0.35 = -0.4551 loss)
I1023 23:38:40.446292 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.27861 (* 0.65 = 2.7811 loss)
I1023 23:38:40.446298 37954 sgd_solver.cpp:106] Iteration 4080, lr = 0.01
I1023 23:39:29.086786 37954 solver.cpp:228] Iteration 4120, loss = 2.19149
I1023 23:39:29.086953 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.29449 (* -0.35 = -0.45307 loss)
I1023 23:39:29.086963 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.06856 (* 0.65 = 2.64456 loss)
I1023 23:39:29.086969 37954 sgd_solver.cpp:106] Iteration 4120, lr = 0.01
I1023 23:40:17.724879 37954 solver.cpp:228] Iteration 4160, loss = 2.27302
I1023 23:40:17.725046 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.29761 (* -0.35 = -0.454163 loss)
I1023 23:40:17.725056 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.19567 (* 0.65 = 2.72719 loss)
I1023 23:40:17.725062 37954 sgd_solver.cpp:106] Iteration 4160, lr = 0.01
I1023 23:41:06.370970 37954 solver.cpp:228] Iteration 4200, loss = 2.29723
I1023 23:41:06.371140 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.29752 (* -0.35 = -0.454133 loss)
I1023 23:41:06.371150 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.23287 (* 0.65 = 2.75137 loss)
I1023 23:41:06.371155 37954 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I1023 23:41:55.017320 37954 solver.cpp:228] Iteration 4240, loss = 2.24583
I1023 23:41:55.017485 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.29827 (* -0.35 = -0.454395 loss)
I1023 23:41:55.017494 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.15419 (* 0.65 = 2.70022 loss)
I1023 23:41:55.017500 37954 sgd_solver.cpp:106] Iteration 4240, lr = 0.01
I1023 23:42:43.680615 37954 solver.cpp:228] Iteration 4280, loss = 2.28337
I1023 23:42:43.680779 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.28784 (* -0.35 = -0.450744 loss)
I1023 23:42:43.680788 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.20633 (* 0.65 = 2.73411 loss)
I1023 23:42:43.680794 37954 sgd_solver.cpp:106] Iteration 4280, lr = 0.01
I1023 23:43:32.316576 37954 solver.cpp:228] Iteration 4320, loss = 2.29038
I1023 23:43:32.316746 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.29191 (* -0.35 = -0.452169 loss)
I1023 23:43:32.316756 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.21931 (* 0.65 = 2.74255 loss)
I1023 23:43:32.316762 37954 sgd_solver.cpp:106] Iteration 4320, lr = 0.01
I1023 23:44:20.973652 37954 solver.cpp:228] Iteration 4360, loss = 2.34092
I1023 23:44:20.973817 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.28822 (* -0.35 = -0.450876 loss)
I1023 23:44:20.973827 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.29507 (* 0.65 = 2.79179 loss)
I1023 23:44:20.973832 37954 sgd_solver.cpp:106] Iteration 4360, lr = 0.01
I1023 23:45:09.603910 37954 solver.cpp:228] Iteration 4400, loss = 2.31333
I1023 23:45:09.604074 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.29393 (* -0.35 = -0.452875 loss)
I1023 23:45:09.604084 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.25571 (* 0.65 = 2.76621 loss)
I1023 23:45:09.604089 37954 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I1023 23:45:58.241883 37954 solver.cpp:228] Iteration 4440, loss = 2.2392
I1023 23:45:58.242048 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.28961 (* -0.35 = -0.451364 loss)
I1023 23:45:58.242058 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.13932 (* 0.65 = 2.69056 loss)
I1023 23:45:58.242063 37954 sgd_solver.cpp:106] Iteration 4440, lr = 0.01
I1023 23:46:46.890111 37954 solver.cpp:228] Iteration 4480, loss = 2.41213
I1023 23:46:46.890276 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.28893 (* -0.35 = -0.451127 loss)
I1023 23:46:46.890286 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.40501 (* 0.65 = 2.86326 loss)
I1023 23:46:46.890291 37954 sgd_solver.cpp:106] Iteration 4480, lr = 0.01
I1023 23:47:09.998015 37954 solver.cpp:337] Iteration 4500, Testing net (#0)
I1023 23:49:04.552178 37954 solver.cpp:404]     Test net output #0: accuracy = 0.11016
I1023 23:49:04.552371 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.44738 (* -0.35 = -0.506584 loss)
I1023 23:49:04.552381 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.69561 (* 0.65 = 3.05215 loss)
I1023 23:49:29.418148 37954 solver.cpp:228] Iteration 4520, loss = 2.23822
I1023 23:49:29.418176 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.28623 (* -0.35 = -0.450182 loss)
I1023 23:49:29.418184 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.136 (* 0.65 = 2.6884 loss)
I1023 23:49:29.418190 37954 sgd_solver.cpp:106] Iteration 4520, lr = 0.01
I1023 23:50:18.097549 37954 solver.cpp:228] Iteration 4560, loss = 2.2566
I1023 23:50:18.097725 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.28632 (* -0.35 = -0.450214 loss)
I1023 23:50:18.097734 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.16433 (* 0.65 = 2.70681 loss)
I1023 23:50:18.097740 37954 sgd_solver.cpp:106] Iteration 4560, lr = 0.01
I1023 23:51:06.746781 37954 solver.cpp:228] Iteration 4600, loss = 2.28814
I1023 23:51:06.746947 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.28197 (* -0.35 = -0.448688 loss)
I1023 23:51:06.746956 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.21051 (* 0.65 = 2.73683 loss)
I1023 23:51:06.746963 37954 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I1023 23:51:55.417727 37954 solver.cpp:228] Iteration 4640, loss = 2.12789
I1023 23:51:55.417891 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.28412 (* -0.35 = -0.449443 loss)
I1023 23:51:55.417901 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.96513 (* 0.65 = 2.57734 loss)
I1023 23:51:55.417906 37954 sgd_solver.cpp:106] Iteration 4640, lr = 0.01
I1023 23:52:44.077564 37954 solver.cpp:228] Iteration 4680, loss = 2.24372
I1023 23:52:44.077723 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.28229 (* -0.35 = -0.448802 loss)
I1023 23:52:44.077733 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.14234 (* 0.65 = 2.69252 loss)
I1023 23:52:44.077739 37954 sgd_solver.cpp:106] Iteration 4680, lr = 0.01
I1023 23:53:32.720976 37954 solver.cpp:228] Iteration 4720, loss = 2.25003
I1023 23:53:32.721145 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.27794 (* -0.35 = -0.447278 loss)
I1023 23:53:32.721154 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.14971 (* 0.65 = 2.69731 loss)
I1023 23:53:32.721160 37954 sgd_solver.cpp:106] Iteration 4720, lr = 0.01
I1023 23:54:21.380511 37954 solver.cpp:228] Iteration 4760, loss = 2.15857
I1023 23:54:21.380678 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.28037 (* -0.35 = -0.448128 loss)
I1023 23:54:21.380692 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.0103 (* 0.65 = 2.60669 loss)
I1023 23:54:21.380697 37954 sgd_solver.cpp:106] Iteration 4760, lr = 0.01
I1023 23:55:10.020324 37954 solver.cpp:228] Iteration 4800, loss = 2.15524
I1023 23:55:10.020493 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.28058 (* -0.35 = -0.448202 loss)
I1023 23:55:10.020503 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.0053 (* 0.65 = 2.60344 loss)
I1023 23:55:10.020509 37954 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I1023 23:55:58.692541 37954 solver.cpp:228] Iteration 4840, loss = 2.1355
I1023 23:55:58.692708 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.27892 (* -0.35 = -0.447623 loss)
I1023 23:55:58.692716 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.97404 (* 0.65 = 2.58312 loss)
I1023 23:55:58.692723 37954 sgd_solver.cpp:106] Iteration 4840, lr = 0.01
I1023 23:56:47.342213 37954 solver.cpp:228] Iteration 4880, loss = 2.28069
I1023 23:56:47.342339 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.2773 (* -0.35 = -0.447055 loss)
I1023 23:56:47.342348 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.19653 (* 0.65 = 2.72774 loss)
I1023 23:56:47.342353 37954 sgd_solver.cpp:106] Iteration 4880, lr = 0.01
I1023 23:57:36.003196 37954 solver.cpp:228] Iteration 4920, loss = 2.14072
I1023 23:57:36.003378 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.27731 (* -0.35 = -0.44706 loss)
I1023 23:57:36.003387 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.9812 (* 0.65 = 2.58778 loss)
I1023 23:57:36.003393 37954 sgd_solver.cpp:106] Iteration 4920, lr = 0.01
I1023 23:58:24.658634 37954 solver.cpp:228] Iteration 4960, loss = 2.11824
I1023 23:58:24.658812 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.27627 (* -0.35 = -0.446696 loss)
I1023 23:58:24.658821 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.94606 (* 0.65 = 2.56494 loss)
I1023 23:58:24.658828 37954 sgd_solver.cpp:106] Iteration 4960, lr = 0.01
I1023 23:59:12.088341 37954 solver.cpp:454] Snapshotting to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_5000.caffemodel
I1023 23:59:17.280858 37954 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_5000.solverstate
I1023 23:59:20.080591 37954 solver.cpp:337] Iteration 5000, Testing net (#0)
I1024 00:01:13.866614 37954 solver.cpp:404]     Test net output #0: accuracy = 0.1078
I1024 00:01:13.866817 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.42748 (* -0.35 = -0.499617 loss)
I1024 00:01:13.866827 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.76643 (* 0.65 = 3.09818 loss)
I1024 00:01:14.408746 37954 solver.cpp:228] Iteration 5000, loss = 2.10873
I1024 00:01:14.408776 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.27845 (* -0.35 = -0.447457 loss)
I1024 00:01:14.408783 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.93259 (* 0.65 = 2.55618 loss)
I1024 00:01:14.408792 37954 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I1024 00:02:03.047652 37954 solver.cpp:228] Iteration 5040, loss = 2.05482
I1024 00:02:03.047829 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.27466 (* -0.35 = -0.446131 loss)
I1024 00:02:03.047838 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.84762 (* 0.65 = 2.50095 loss)
I1024 00:02:03.047844 37954 sgd_solver.cpp:106] Iteration 5040, lr = 0.01
I1024 00:02:51.718807 37954 solver.cpp:228] Iteration 5080, loss = 2.07197
I1024 00:02:51.718974 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.27425 (* -0.35 = -0.445988 loss)
I1024 00:02:51.718983 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.87378 (* 0.65 = 2.51796 loss)
I1024 00:02:51.718989 37954 sgd_solver.cpp:106] Iteration 5080, lr = 0.01
I1024 00:03:40.352984 37954 solver.cpp:228] Iteration 5120, loss = 2.18371
I1024 00:03:40.353145 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.27144 (* -0.35 = -0.445003 loss)
I1024 00:03:40.353155 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.04418 (* 0.65 = 2.62872 loss)
I1024 00:03:40.353160 37954 sgd_solver.cpp:106] Iteration 5120, lr = 0.01
I1024 00:04:28.982558 37954 solver.cpp:228] Iteration 5160, loss = 2.18456
I1024 00:04:28.982727 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.26677 (* -0.35 = -0.443371 loss)
I1024 00:04:28.982736 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.04297 (* 0.65 = 2.62793 loss)
I1024 00:04:28.982741 37954 sgd_solver.cpp:106] Iteration 5160, lr = 0.01
I1024 00:05:17.612880 37954 solver.cpp:228] Iteration 5200, loss = 2.18413
I1024 00:05:17.613042 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.26368 (* -0.35 = -0.442287 loss)
I1024 00:05:17.613052 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.04064 (* 0.65 = 2.62641 loss)
I1024 00:05:17.613059 37954 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I1024 00:06:06.270385 37954 solver.cpp:228] Iteration 5240, loss = 2.1068
I1024 00:06:06.270550 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.26735 (* -0.35 = -0.443573 loss)
I1024 00:06:06.270560 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.92365 (* 0.65 = 2.55037 loss)
I1024 00:06:06.270565 37954 sgd_solver.cpp:106] Iteration 5240, lr = 0.01
I1024 00:06:54.924021 37954 solver.cpp:228] Iteration 5280, loss = 2.23372
I1024 00:06:54.924206 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.26523 (* -0.35 = -0.442832 loss)
I1024 00:06:54.924216 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.11778 (* 0.65 = 2.67656 loss)
I1024 00:06:54.924222 37954 sgd_solver.cpp:106] Iteration 5280, lr = 0.01
I1024 00:07:43.574232 37954 solver.cpp:228] Iteration 5320, loss = 2.19097
I1024 00:07:43.574401 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.26271 (* -0.35 = -0.44195 loss)
I1024 00:07:43.574410 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.05065 (* 0.65 = 2.63292 loss)
I1024 00:07:43.574416 37954 sgd_solver.cpp:106] Iteration 5320, lr = 0.01
I1024 00:08:32.238874 37954 solver.cpp:228] Iteration 5360, loss = 2.18797
I1024 00:08:32.239044 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.26758 (* -0.35 = -0.443651 loss)
I1024 00:08:32.239054 37954 solver.cpp:244]     Train net output #1: loss_p2 = 4.04865 (* 0.65 = 2.63162 loss)
I1024 00:08:32.239060 37954 sgd_solver.cpp:106] Iteration 5360, lr = 0.01
I1024 00:09:20.906904 37954 solver.cpp:228] Iteration 5400, loss = 2.02094
I1024 00:09:20.907065 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.26391 (* -0.35 = -0.44237 loss)
I1024 00:09:20.907074 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.7897 (* 0.65 = 2.46331 loss)
I1024 00:09:20.907080 37954 sgd_solver.cpp:106] Iteration 5400, lr = 0.01
I1024 00:10:09.575083 37954 solver.cpp:228] Iteration 5440, loss = 1.95316
I1024 00:10:09.575253 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.26547 (* -0.35 = -0.442916 loss)
I1024 00:10:09.575263 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.68627 (* 0.65 = 2.39607 loss)
I1024 00:10:09.575268 37954 sgd_solver.cpp:106] Iteration 5440, lr = 0.01
I1024 00:10:58.225879 37954 solver.cpp:228] Iteration 5480, loss = 1.87621
I1024 00:10:58.226047 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.26255 (* -0.35 = -0.441891 loss)
I1024 00:10:58.226058 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.56631 (* 0.65 = 2.3181 loss)
I1024 00:10:58.226063 37954 sgd_solver.cpp:106] Iteration 5480, lr = 0.01
I1024 00:11:21.340225 37954 solver.cpp:337] Iteration 5500, Testing net (#0)
I1024 00:13:15.679997 37954 solver.cpp:404]     Test net output #0: accuracy = 0.10964
I1024 00:13:15.680162 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.39922 (* -0.35 = -0.489726 loss)
I1024 00:13:15.680172 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.72918 (* 0.65 = 3.07397 loss)
I1024 00:13:40.532927 37954 solver.cpp:228] Iteration 5520, loss = 1.96608
I1024 00:13:40.532943 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.25697 (* -0.35 = -0.439939 loss)
I1024 00:13:40.532963 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.70157 (* 0.65 = 2.40602 loss)
I1024 00:13:40.532968 37954 sgd_solver.cpp:106] Iteration 5520, lr = 0.01
I1024 00:14:29.187842 37954 solver.cpp:228] Iteration 5560, loss = 2.03523
I1024 00:14:29.188010 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.26296 (* -0.35 = -0.442035 loss)
I1024 00:14:29.188019 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.81118 (* 0.65 = 2.47726 loss)
I1024 00:14:29.188025 37954 sgd_solver.cpp:106] Iteration 5560, lr = 0.01
I1024 00:15:17.808493 37954 solver.cpp:228] Iteration 5600, loss = 2.07543
I1024 00:15:17.808629 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.25946 (* -0.35 = -0.440811 loss)
I1024 00:15:17.808640 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.87115 (* 0.65 = 2.51624 loss)
I1024 00:15:17.808645 37954 sgd_solver.cpp:106] Iteration 5600, lr = 0.01
I1024 00:16:06.424842 37954 solver.cpp:228] Iteration 5640, loss = 1.85864
I1024 00:16:06.425014 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.2562 (* -0.35 = -0.43967 loss)
I1024 00:16:06.425024 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.53586 (* 0.65 = 2.29831 loss)
I1024 00:16:06.425029 37954 sgd_solver.cpp:106] Iteration 5640, lr = 0.01
I1024 00:16:55.066741 37954 solver.cpp:228] Iteration 5680, loss = 1.97955
I1024 00:16:55.066925 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.25974 (* -0.35 = -0.440909 loss)
I1024 00:16:55.066933 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.72378 (* 0.65 = 2.42046 loss)
I1024 00:16:55.066939 37954 sgd_solver.cpp:106] Iteration 5680, lr = 0.01
I1024 00:17:43.712366 37954 solver.cpp:228] Iteration 5720, loss = 1.81856
I1024 00:17:43.712537 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.25939 (* -0.35 = -0.440788 loss)
I1024 00:17:43.712546 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.47592 (* 0.65 = 2.25935 loss)
I1024 00:17:43.712551 37954 sgd_solver.cpp:106] Iteration 5720, lr = 0.01
I1024 00:18:32.354429 37954 solver.cpp:228] Iteration 5760, loss = 2.15211
I1024 00:18:32.354604 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.25897 (* -0.35 = -0.440641 loss)
I1024 00:18:32.354614 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.98885 (* 0.65 = 2.59275 loss)
I1024 00:18:32.354619 37954 sgd_solver.cpp:106] Iteration 5760, lr = 0.01
I1024 00:19:20.998746 37954 solver.cpp:228] Iteration 5800, loss = 1.79466
I1024 00:19:20.998915 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.25594 (* -0.35 = -0.439581 loss)
I1024 00:19:20.998925 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.4373 (* 0.65 = 2.23424 loss)
I1024 00:19:20.998931 37954 sgd_solver.cpp:106] Iteration 5800, lr = 0.01
I1024 00:20:09.645464 37954 solver.cpp:228] Iteration 5840, loss = 2.14635
I1024 00:20:09.645632 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.25226 (* -0.35 = -0.438292 loss)
I1024 00:20:09.645642 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.97638 (* 0.65 = 2.58464 loss)
I1024 00:20:09.645648 37954 sgd_solver.cpp:106] Iteration 5840, lr = 0.01
I1024 00:20:58.286697 37954 solver.cpp:228] Iteration 5880, loss = 1.8023
I1024 00:20:58.286864 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.26024 (* -0.35 = -0.441083 loss)
I1024 00:20:58.286873 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.45136 (* 0.65 = 2.24339 loss)
I1024 00:20:58.286878 37954 sgd_solver.cpp:106] Iteration 5880, lr = 0.01
I1024 00:21:46.933495 37954 solver.cpp:228] Iteration 5920, loss = 1.93574
I1024 00:21:46.933663 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.25414 (* -0.35 = -0.438947 loss)
I1024 00:21:46.933672 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.65337 (* 0.65 = 2.37469 loss)
I1024 00:21:46.933678 37954 sgd_solver.cpp:106] Iteration 5920, lr = 0.01
I1024 00:22:35.817981 37954 solver.cpp:228] Iteration 5960, loss = 1.90914
I1024 00:22:35.818251 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.25078 (* -0.35 = -0.437774 loss)
I1024 00:22:35.818261 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.61064 (* 0.65 = 2.34691 loss)
I1024 00:22:35.818271 37954 sgd_solver.cpp:106] Iteration 5960, lr = 0.01
I1024 00:23:23.628490 37954 solver.cpp:454] Snapshotting to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_6000.caffemodel
I1024 00:23:28.820610 37954 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_6000.solverstate
I1024 00:23:31.584179 37954 solver.cpp:337] Iteration 6000, Testing net (#0)
I1024 00:25:25.337642 37954 solver.cpp:404]     Test net output #0: accuracy = 0.11358
I1024 00:25:25.337878 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.38044 (* -0.35 = -0.483152 loss)
I1024 00:25:25.337888 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.73675 (* 0.65 = 3.07889 loss)
I1024 00:25:25.877773 37954 solver.cpp:228] Iteration 6000, loss = 1.99706
I1024 00:25:25.877840 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.25058 (* -0.35 = -0.437702 loss)
I1024 00:25:25.877851 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.74579 (* 0.65 = 2.43476 loss)
I1024 00:25:25.877861 37954 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I1024 00:26:14.917765 37954 solver.cpp:228] Iteration 6040, loss = 1.93803
I1024 00:26:14.918040 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.25363 (* -0.35 = -0.438769 loss)
I1024 00:26:14.918050 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.65661 (* 0.65 = 2.3768 loss)
I1024 00:26:14.918058 37954 sgd_solver.cpp:106] Iteration 6040, lr = 0.01
I1024 00:27:03.936970 37954 solver.cpp:228] Iteration 6080, loss = 1.98788
I1024 00:27:03.937249 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.24946 (* -0.35 = -0.43731 loss)
I1024 00:27:03.937258 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.73107 (* 0.65 = 2.42519 loss)
I1024 00:27:03.937268 37954 sgd_solver.cpp:106] Iteration 6080, lr = 0.01
I1024 00:27:52.969414 37954 solver.cpp:228] Iteration 6120, loss = 2.018
I1024 00:27:52.969686 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.24723 (* -0.35 = -0.436531 loss)
I1024 00:27:52.969697 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.7762 (* 0.65 = 2.45453 loss)
I1024 00:27:52.969707 37954 sgd_solver.cpp:106] Iteration 6120, lr = 0.01
I1024 00:28:41.969295 37954 solver.cpp:228] Iteration 6160, loss = 2.03297
I1024 00:28:41.969557 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.24999 (* -0.35 = -0.437498 loss)
I1024 00:28:41.969565 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.80071 (* 0.65 = 2.47046 loss)
I1024 00:28:41.969571 37954 sgd_solver.cpp:106] Iteration 6160, lr = 0.01
I1024 00:29:30.672621 37954 solver.cpp:228] Iteration 6200, loss = 1.94534
I1024 00:29:30.672852 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.24853 (* -0.35 = -0.436985 loss)
I1024 00:29:30.672861 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.66511 (* 0.65 = 2.38232 loss)
I1024 00:29:30.672870 37954 sgd_solver.cpp:106] Iteration 6200, lr = 0.01
I1024 00:30:19.733227 37954 solver.cpp:228] Iteration 6240, loss = 1.95009
I1024 00:30:19.733448 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.24319 (* -0.35 = -0.435117 loss)
I1024 00:30:19.733458 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.66955 (* 0.65 = 2.38521 loss)
I1024 00:30:19.733466 37954 sgd_solver.cpp:106] Iteration 6240, lr = 0.01
I1024 00:31:08.786192 37954 solver.cpp:228] Iteration 6280, loss = 1.88969
I1024 00:31:08.786406 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.24097 (* -0.35 = -0.434339 loss)
I1024 00:31:08.786417 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.57543 (* 0.65 = 2.32403 loss)
I1024 00:31:08.786425 37954 sgd_solver.cpp:106] Iteration 6280, lr = 0.01
I1024 00:31:57.402225 37954 solver.cpp:228] Iteration 6320, loss = 2.01755
I1024 00:31:57.402421 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.24784 (* -0.35 = -0.436744 loss)
I1024 00:31:57.402431 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.77584 (* 0.65 = 2.45429 loss)
I1024 00:31:57.402437 37954 sgd_solver.cpp:106] Iteration 6320, lr = 0.01
I1024 00:32:45.983909 37954 solver.cpp:228] Iteration 6360, loss = 1.85232
I1024 00:32:45.984069 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23971 (* -0.35 = -0.433897 loss)
I1024 00:32:45.984078 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.51725 (* 0.65 = 2.28621 loss)
I1024 00:32:45.984084 37954 sgd_solver.cpp:106] Iteration 6360, lr = 0.01
I1024 00:33:34.580796 37954 solver.cpp:228] Iteration 6400, loss = 1.96633
I1024 00:33:34.580934 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23925 (* -0.35 = -0.433738 loss)
I1024 00:33:34.580942 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.69241 (* 0.65 = 2.40007 loss)
I1024 00:33:34.580948 37954 sgd_solver.cpp:106] Iteration 6400, lr = 0.01
I1024 00:34:23.177758 37954 solver.cpp:228] Iteration 6440, loss = 2.04029
I1024 00:34:23.177904 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.24145 (* -0.35 = -0.434509 loss)
I1024 00:34:23.177913 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.80739 (* 0.65 = 2.4748 loss)
I1024 00:34:23.177919 37954 sgd_solver.cpp:106] Iteration 6440, lr = 0.01
I1024 00:35:12.174644 37954 solver.cpp:228] Iteration 6480, loss = 1.93607
I1024 00:35:12.174896 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.24612 (* -0.35 = -0.43614 loss)
I1024 00:35:12.174906 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.64956 (* 0.65 = 2.37221 loss)
I1024 00:35:12.174914 37954 sgd_solver.cpp:106] Iteration 6480, lr = 0.01
I1024 00:35:35.472693 37954 solver.cpp:337] Iteration 6500, Testing net (#0)
I1024 00:37:29.915134 37954 solver.cpp:404]     Test net output #0: accuracy = 0.11404
I1024 00:37:29.915397 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.36671 (* -0.35 = -0.47835 loss)
I1024 00:37:29.915407 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.74821 (* 0.65 = 3.08634 loss)
I1024 00:37:54.994702 37954 solver.cpp:228] Iteration 6520, loss = 2.03834
I1024 00:37:54.994762 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23537 (* -0.35 = -0.432379 loss)
I1024 00:37:54.994771 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.8011 (* 0.65 = 2.47072 loss)
I1024 00:37:54.994779 37954 sgd_solver.cpp:106] Iteration 6520, lr = 0.01
I1024 00:38:43.732273 37954 solver.cpp:228] Iteration 6560, loss = 1.8976
I1024 00:38:43.732445 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23865 (* -0.35 = -0.433526 loss)
I1024 00:38:43.732453 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.58634 (* 0.65 = 2.33112 loss)
I1024 00:38:43.732465 37954 sgd_solver.cpp:106] Iteration 6560, lr = 0.01
I1024 00:39:32.373934 37954 solver.cpp:228] Iteration 6600, loss = 1.92879
I1024 00:39:32.374158 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23419 (* -0.35 = -0.431967 loss)
I1024 00:39:32.374168 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.63194 (* 0.65 = 2.36076 loss)
I1024 00:39:32.374177 37954 sgd_solver.cpp:106] Iteration 6600, lr = 0.01
I1024 00:40:21.448460 37954 solver.cpp:228] Iteration 6640, loss = 1.77138
I1024 00:40:21.448698 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.2379 (* -0.35 = -0.433266 loss)
I1024 00:40:21.448707 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.39176 (* 0.65 = 2.20465 loss)
I1024 00:40:21.448716 37954 sgd_solver.cpp:106] Iteration 6640, lr = 0.01
I1024 00:41:10.511878 37954 solver.cpp:228] Iteration 6680, loss = 1.69547
I1024 00:41:10.512114 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23836 (* -0.35 = -0.433425 loss)
I1024 00:41:10.512125 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.27522 (* 0.65 = 2.12889 loss)
I1024 00:41:10.512133 37954 sgd_solver.cpp:106] Iteration 6680, lr = 0.01
I1024 00:41:59.566069 37954 solver.cpp:228] Iteration 6720, loss = 1.97769
I1024 00:41:59.566292 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23766 (* -0.35 = -0.43318 loss)
I1024 00:41:59.566301 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.70903 (* 0.65 = 2.41087 loss)
I1024 00:41:59.566309 37954 sgd_solver.cpp:106] Iteration 6720, lr = 0.01
I1024 00:42:48.602664 37954 solver.cpp:228] Iteration 6760, loss = 1.88098
I1024 00:42:48.602888 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23455 (* -0.35 = -0.432093 loss)
I1024 00:42:48.602898 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.55857 (* 0.65 = 2.31307 loss)
I1024 00:42:48.602907 37954 sgd_solver.cpp:106] Iteration 6760, lr = 0.01
I1024 00:43:37.656069 37954 solver.cpp:228] Iteration 6800, loss = 1.79658
I1024 00:43:37.656296 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23626 (* -0.35 = -0.432692 loss)
I1024 00:43:37.656304 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.42965 (* 0.65 = 2.22927 loss)
I1024 00:43:37.656313 37954 sgd_solver.cpp:106] Iteration 6800, lr = 0.01
I1024 00:44:26.429832 37954 solver.cpp:228] Iteration 6840, loss = 1.86512
I1024 00:44:26.430008 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23559 (* -0.35 = -0.432456 loss)
I1024 00:44:26.430025 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.53474 (* 0.65 = 2.29758 loss)
I1024 00:44:26.430032 37954 sgd_solver.cpp:106] Iteration 6840, lr = 0.01
I1024 00:45:15.023408 37954 solver.cpp:228] Iteration 6880, loss = 1.7347
I1024 00:45:15.023620 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23743 (* -0.35 = -0.433101 loss)
I1024 00:45:15.023630 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.33508 (* 0.65 = 2.1678 loss)
I1024 00:45:15.023636 37954 sgd_solver.cpp:106] Iteration 6880, lr = 0.01
I1024 00:46:03.595307 37954 solver.cpp:228] Iteration 6920, loss = 1.81132
I1024 00:46:03.595445 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.234 (* -0.35 = -0.4319 loss)
I1024 00:46:03.595455 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.45111 (* 0.65 = 2.24322 loss)
I1024 00:46:03.595460 37954 sgd_solver.cpp:106] Iteration 6920, lr = 0.01
I1024 00:46:52.172890 37954 solver.cpp:228] Iteration 6960, loss = 1.68251
I1024 00:46:52.173043 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22829 (* -0.35 = -0.429903 loss)
I1024 00:46:52.173058 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.24986 (* 0.65 = 2.11241 loss)
I1024 00:46:52.173063 37954 sgd_solver.cpp:106] Iteration 6960, lr = 0.01
I1024 00:47:39.527868 37954 solver.cpp:454] Snapshotting to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_7000.caffemodel
I1024 00:47:44.771786 37954 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_7000.solverstate
I1024 00:47:47.589170 37954 solver.cpp:337] Iteration 7000, Testing net (#0)
I1024 00:49:41.236657 37954 solver.cpp:404]     Test net output #0: accuracy = 0.111
I1024 00:49:41.236909 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.34393 (* -0.35 = -0.470375 loss)
I1024 00:49:41.236919 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.79069 (* 0.65 = 3.11395 loss)
I1024 00:49:41.778146 37954 solver.cpp:228] Iteration 7000, loss = 1.76877
I1024 00:49:41.778200 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22618 (* -0.35 = -0.429164 loss)
I1024 00:49:41.778208 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.38144 (* 0.65 = 2.19794 loss)
I1024 00:49:41.778218 37954 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I1024 00:50:30.370417 37954 solver.cpp:228] Iteration 7040, loss = 1.9231
I1024 00:50:30.370625 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23077 (* -0.35 = -0.430769 loss)
I1024 00:50:30.370635 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.62134 (* 0.65 = 2.35387 loss)
I1024 00:50:30.370640 37954 sgd_solver.cpp:106] Iteration 7040, lr = 0.01
I1024 00:51:18.955865 37954 solver.cpp:228] Iteration 7080, loss = 1.80998
I1024 00:51:18.956012 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.2315 (* -0.35 = -0.431024 loss)
I1024 00:51:18.956027 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.44769 (* 0.65 = 2.241 loss)
I1024 00:51:18.956032 37954 sgd_solver.cpp:106] Iteration 7080, lr = 0.01
I1024 00:52:07.547981 37954 solver.cpp:228] Iteration 7120, loss = 1.90829
I1024 00:52:07.548152 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.23088 (* -0.35 = -0.43081 loss)
I1024 00:52:07.548161 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.59862 (* 0.65 = 2.3391 loss)
I1024 00:52:07.548167 37954 sgd_solver.cpp:106] Iteration 7120, lr = 0.01
I1024 00:52:56.125916 37954 solver.cpp:228] Iteration 7160, loss = 1.72684
I1024 00:52:56.126073 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22965 (* -0.35 = -0.430378 loss)
I1024 00:52:56.126083 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.31879 (* 0.65 = 2.15722 loss)
I1024 00:52:56.126088 37954 sgd_solver.cpp:106] Iteration 7160, lr = 0.01
I1024 00:53:44.705024 37954 solver.cpp:228] Iteration 7200, loss = 1.7282
I1024 00:53:44.705169 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22943 (* -0.35 = -0.430299 loss)
I1024 00:53:44.705185 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.32077 (* 0.65 = 2.1585 loss)
I1024 00:53:44.705191 37954 sgd_solver.cpp:106] Iteration 7200, lr = 0.01
I1024 00:54:33.300478 37954 solver.cpp:228] Iteration 7240, loss = 1.78591
I1024 00:54:33.300642 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22776 (* -0.35 = -0.429717 loss)
I1024 00:54:33.300658 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.40866 (* 0.65 = 2.21563 loss)
I1024 00:54:33.300663 37954 sgd_solver.cpp:106] Iteration 7240, lr = 0.01
I1024 00:55:21.877576 37954 solver.cpp:228] Iteration 7280, loss = 1.49481
I1024 00:55:21.877722 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.2264 (* -0.35 = -0.429239 loss)
I1024 00:55:21.877732 37954 solver.cpp:244]     Train net output #1: loss_p2 = 2.96008 (* 0.65 = 1.92405 loss)
I1024 00:55:21.877737 37954 sgd_solver.cpp:106] Iteration 7280, lr = 0.01
I1024 00:56:10.656306 37954 solver.cpp:228] Iteration 7320, loss = 1.62026
I1024 00:56:10.656584 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22922 (* -0.35 = -0.430227 loss)
I1024 00:56:10.656594 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.1546 (* 0.65 = 2.05049 loss)
I1024 00:56:10.656604 37954 sgd_solver.cpp:106] Iteration 7320, lr = 0.01
I1024 00:56:59.644614 37954 solver.cpp:228] Iteration 7360, loss = 1.82476
I1024 00:56:59.644884 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22889 (* -0.35 = -0.430112 loss)
I1024 00:56:59.644894 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.46904 (* 0.65 = 2.25487 loss)
I1024 00:56:59.644901 37954 sgd_solver.cpp:106] Iteration 7360, lr = 0.01
I1024 00:57:48.280172 37954 solver.cpp:228] Iteration 7400, loss = 1.7868
I1024 00:57:48.280295 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22576 (* -0.35 = -0.429014 loss)
I1024 00:57:48.280304 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.40894 (* 0.65 = 2.21581 loss)
I1024 00:57:48.280315 37954 sgd_solver.cpp:106] Iteration 7400, lr = 0.01
I1024 00:58:36.908324 37954 solver.cpp:228] Iteration 7440, loss = 1.78912
I1024 00:58:36.908496 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22365 (* -0.35 = -0.428277 loss)
I1024 00:58:36.908505 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.41138 (* 0.65 = 2.2174 loss)
I1024 00:58:36.908511 37954 sgd_solver.cpp:106] Iteration 7440, lr = 0.01
I1024 00:59:25.546387 37954 solver.cpp:228] Iteration 7480, loss = 1.73502
I1024 00:59:25.546555 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22619 (* -0.35 = -0.429165 loss)
I1024 00:59:25.546564 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.32952 (* 0.65 = 2.16419 loss)
I1024 00:59:25.546571 37954 sgd_solver.cpp:106] Iteration 7480, lr = 0.01
I1024 00:59:48.779091 37954 solver.cpp:337] Iteration 7500, Testing net (#0)
I1024 01:01:43.168231 37954 solver.cpp:404]     Test net output #0: accuracy = 0.1122
I1024 01:01:43.168512 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.33009 (* -0.35 = -0.465531 loss)
I1024 01:01:43.168522 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.84384 (* 0.65 = 3.1485 loss)
I1024 01:02:08.047823 37954 solver.cpp:228] Iteration 7520, loss = 1.47362
I1024 01:02:08.047878 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22632 (* -0.35 = -0.429213 loss)
I1024 01:02:08.047886 37954 solver.cpp:244]     Train net output #1: loss_p2 = 2.92743 (* 0.65 = 1.90283 loss)
I1024 01:02:08.047891 37954 sgd_solver.cpp:106] Iteration 7520, lr = 0.01
I1024 01:02:56.717541 37954 solver.cpp:228] Iteration 7560, loss = 1.72651
I1024 01:02:56.717751 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22432 (* -0.35 = -0.428513 loss)
I1024 01:02:56.717759 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.31542 (* 0.65 = 2.15502 loss)
I1024 01:02:56.717766 37954 sgd_solver.cpp:106] Iteration 7560, lr = 0.01
I1024 01:03:45.387977 37954 solver.cpp:228] Iteration 7600, loss = 1.65075
I1024 01:03:45.388140 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22578 (* -0.35 = -0.429024 loss)
I1024 01:03:45.388150 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.19965 (* 0.65 = 2.07977 loss)
I1024 01:03:45.388155 37954 sgd_solver.cpp:106] Iteration 7600, lr = 0.01
I1024 01:04:34.041070 37954 solver.cpp:228] Iteration 7640, loss = 1.8358
I1024 01:04:34.041260 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22412 (* -0.35 = -0.428442 loss)
I1024 01:04:34.041270 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.48345 (* 0.65 = 2.26424 loss)
I1024 01:04:34.041275 37954 sgd_solver.cpp:106] Iteration 7640, lr = 0.01
I1024 01:05:22.675715 37954 solver.cpp:228] Iteration 7680, loss = 1.85076
I1024 01:05:22.675886 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21755 (* -0.35 = -0.426144 loss)
I1024 01:05:22.675895 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.50293 (* 0.65 = 2.2769 loss)
I1024 01:05:22.675901 37954 sgd_solver.cpp:106] Iteration 7680, lr = 0.01
I1024 01:06:11.570598 37954 solver.cpp:228] Iteration 7720, loss = 1.57342
I1024 01:06:11.570868 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22143 (* -0.35 = -0.427502 loss)
I1024 01:06:11.570878 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.07834 (* 0.65 = 2.00092 loss)
I1024 01:06:11.570886 37954 sgd_solver.cpp:106] Iteration 7720, lr = 0.01
I1024 01:07:00.594694 37954 solver.cpp:228] Iteration 7760, loss = 1.60761
I1024 01:07:00.594954 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22185 (* -0.35 = -0.427647 loss)
I1024 01:07:00.594964 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.13117 (* 0.65 = 2.03526 loss)
I1024 01:07:00.594974 37954 sgd_solver.cpp:106] Iteration 7760, lr = 0.01
I1024 01:07:49.587682 37954 solver.cpp:228] Iteration 7800, loss = 1.56851
I1024 01:07:49.587941 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22093 (* -0.35 = -0.427326 loss)
I1024 01:07:49.587951 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.07051 (* 0.65 = 1.99583 loss)
I1024 01:07:49.587957 37954 sgd_solver.cpp:106] Iteration 7800, lr = 0.01
I1024 01:08:38.217284 37954 solver.cpp:228] Iteration 7840, loss = 1.57638
I1024 01:08:38.217458 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22097 (* -0.35 = -0.427341 loss)
I1024 01:08:38.217468 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.08265 (* 0.65 = 2.00372 loss)
I1024 01:08:38.217473 37954 sgd_solver.cpp:106] Iteration 7840, lr = 0.01
I1024 01:09:26.864270 37954 solver.cpp:228] Iteration 7880, loss = 1.68724
I1024 01:09:26.864436 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.22271 (* -0.35 = -0.42795 loss)
I1024 01:09:26.864445 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.25415 (* 0.65 = 2.11519 loss)
I1024 01:09:26.864451 37954 sgd_solver.cpp:106] Iteration 7880, lr = 0.01
I1024 01:10:15.501840 37954 solver.cpp:228] Iteration 7920, loss = 1.6122
I1024 01:10:15.502007 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21724 (* -0.35 = -0.426036 loss)
I1024 01:10:15.502015 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.13574 (* 0.65 = 2.03823 loss)
I1024 01:10:15.502022 37954 sgd_solver.cpp:106] Iteration 7920, lr = 0.01
I1024 01:11:04.168751 37954 solver.cpp:228] Iteration 7960, loss = 1.83213
I1024 01:11:04.168916 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.2171 (* -0.35 = -0.425987 loss)
I1024 01:11:04.168926 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.47403 (* 0.65 = 2.25812 loss)
I1024 01:11:04.168931 37954 sgd_solver.cpp:106] Iteration 7960, lr = 0.01
I1024 01:11:51.586865 37954 solver.cpp:454] Snapshotting to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_8000.caffemodel
I1024 01:11:56.807050 37954 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_8000.solverstate
I1024 01:11:59.610213 37954 solver.cpp:337] Iteration 8000, Testing net (#0)
I1024 01:13:53.385754 37954 solver.cpp:404]     Test net output #0: accuracy = 0.10872
I1024 01:13:53.385995 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.32114 (* -0.35 = -0.462398 loss)
I1024 01:13:53.386004 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.84334 (* 0.65 = 3.14817 loss)
I1024 01:13:53.916543 37954 solver.cpp:228] Iteration 8000, loss = 1.5645
I1024 01:13:53.916573 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21781 (* -0.35 = -0.426234 loss)
I1024 01:13:53.916580 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.06266 (* 0.65 = 1.99073 loss)
I1024 01:13:53.916589 37954 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I1024 01:14:42.542007 37954 solver.cpp:228] Iteration 8040, loss = 1.75669
I1024 01:14:42.542192 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.2164 (* -0.35 = -0.425741 loss)
I1024 01:14:42.542202 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.35759 (* 0.65 = 2.18243 loss)
I1024 01:14:42.542208 37954 sgd_solver.cpp:106] Iteration 8040, lr = 0.01
I1024 01:15:31.219163 37954 solver.cpp:228] Iteration 8080, loss = 1.55384
I1024 01:15:31.219429 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21814 (* -0.35 = -0.42635 loss)
I1024 01:15:31.219439 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.04645 (* 0.65 = 1.98019 loss)
I1024 01:15:31.219444 37954 sgd_solver.cpp:106] Iteration 8080, lr = 0.01
I1024 01:16:19.861482 37954 solver.cpp:228] Iteration 8120, loss = 1.57329
I1024 01:16:19.861647 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21446 (* -0.35 = -0.425061 loss)
I1024 01:16:19.861656 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.07439 (* 0.65 = 1.99836 loss)
I1024 01:16:19.861662 37954 sgd_solver.cpp:106] Iteration 8120, lr = 0.01
I1024 01:17:08.511296 37954 solver.cpp:228] Iteration 8160, loss = 1.52296
I1024 01:17:08.511461 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21607 (* -0.35 = -0.425623 loss)
I1024 01:17:08.511471 37954 solver.cpp:244]     Train net output #1: loss_p2 = 2.99782 (* 0.65 = 1.94858 loss)
I1024 01:17:08.511477 37954 sgd_solver.cpp:106] Iteration 8160, lr = 0.01
I1024 01:17:57.162881 37954 solver.cpp:228] Iteration 8200, loss = 1.40135
I1024 01:17:57.163046 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21699 (* -0.35 = -0.425946 loss)
I1024 01:17:57.163056 37954 solver.cpp:244]     Train net output #1: loss_p2 = 2.81122 (* 0.65 = 1.82729 loss)
I1024 01:17:57.163063 37954 sgd_solver.cpp:106] Iteration 8200, lr = 0.01
I1024 01:18:45.794443 37954 solver.cpp:228] Iteration 8240, loss = 1.77462
I1024 01:18:45.794617 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21371 (* -0.35 = -0.424799 loss)
I1024 01:18:45.794627 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.38373 (* 0.65 = 2.19942 loss)
I1024 01:18:45.794632 37954 sgd_solver.cpp:106] Iteration 8240, lr = 0.01
I1024 01:19:34.450093 37954 solver.cpp:228] Iteration 8280, loss = 1.80447
I1024 01:19:34.450264 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21463 (* -0.35 = -0.425119 loss)
I1024 01:19:34.450274 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.43013 (* 0.65 = 2.22959 loss)
I1024 01:19:34.450280 37954 sgd_solver.cpp:106] Iteration 8280, lr = 0.01
I1024 01:20:23.101488 37954 solver.cpp:228] Iteration 8320, loss = 1.79623
I1024 01:20:23.101662 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21501 (* -0.35 = -0.425253 loss)
I1024 01:20:23.101672 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.41767 (* 0.65 = 2.22149 loss)
I1024 01:20:23.101677 37954 sgd_solver.cpp:106] Iteration 8320, lr = 0.01
I1024 01:21:11.720402 37954 solver.cpp:228] Iteration 8360, loss = 1.66749
I1024 01:21:11.720566 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21576 (* -0.35 = -0.425516 loss)
I1024 01:21:11.720574 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.22001 (* 0.65 = 2.093 loss)
I1024 01:21:11.720580 37954 sgd_solver.cpp:106] Iteration 8360, lr = 0.01
I1024 01:22:00.362638 37954 solver.cpp:228] Iteration 8400, loss = 1.76347
I1024 01:22:00.362802 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.2102 (* -0.35 = -0.423571 loss)
I1024 01:22:00.362812 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.36468 (* 0.65 = 2.18704 loss)
I1024 01:22:00.362818 37954 sgd_solver.cpp:106] Iteration 8400, lr = 0.01
I1024 01:22:48.977988 37954 solver.cpp:228] Iteration 8440, loss = 1.49702
I1024 01:22:48.978173 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21401 (* -0.35 = -0.424904 loss)
I1024 01:22:48.978183 37954 solver.cpp:244]     Train net output #1: loss_p2 = 2.9568 (* 0.65 = 1.92192 loss)
I1024 01:22:48.978188 37954 sgd_solver.cpp:106] Iteration 8440, lr = 0.01
I1024 01:23:37.620548 37954 solver.cpp:228] Iteration 8480, loss = 1.55221
I1024 01:23:37.620715 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21231 (* -0.35 = -0.424307 loss)
I1024 01:23:37.620725 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.0408 (* 0.65 = 1.97652 loss)
I1024 01:23:37.620730 37954 sgd_solver.cpp:106] Iteration 8480, lr = 0.01
I1024 01:24:00.723955 37954 solver.cpp:337] Iteration 8500, Testing net (#0)
I1024 01:25:55.075788 37954 solver.cpp:404]     Test net output #0: accuracy = 0.10422
I1024 01:25:55.075959 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.30971 (* -0.35 = -0.458398 loss)
I1024 01:25:55.075968 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.98598 (* 0.65 = 3.24089 loss)
I1024 01:26:19.931823 37954 solver.cpp:228] Iteration 8520, loss = 1.63035
I1024 01:26:19.931851 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21457 (* -0.35 = -0.425098 loss)
I1024 01:26:19.931859 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.16223 (* 0.65 = 2.05545 loss)
I1024 01:26:19.931864 37954 sgd_solver.cpp:106] Iteration 8520, lr = 0.01
I1024 01:27:08.582641 37954 solver.cpp:228] Iteration 8560, loss = 1.60511
I1024 01:27:08.582815 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21361 (* -0.35 = -0.424763 loss)
I1024 01:27:08.582825 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.12288 (* 0.65 = 2.02987 loss)
I1024 01:27:08.582831 37954 sgd_solver.cpp:106] Iteration 8560, lr = 0.01
I1024 01:27:57.227965 37954 solver.cpp:228] Iteration 8600, loss = 1.43065
I1024 01:27:57.228130 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.2121 (* -0.35 = -0.424234 loss)
I1024 01:27:57.228140 37954 solver.cpp:244]     Train net output #1: loss_p2 = 2.85366 (* 0.65 = 1.85488 loss)
I1024 01:27:57.228147 37954 sgd_solver.cpp:106] Iteration 8600, lr = 0.01
I1024 01:28:45.874861 37954 solver.cpp:228] Iteration 8640, loss = 1.75148
I1024 01:28:45.875033 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21404 (* -0.35 = -0.424914 loss)
I1024 01:28:45.875042 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.3483 (* 0.65 = 2.1764 loss)
I1024 01:28:45.875048 37954 sgd_solver.cpp:106] Iteration 8640, lr = 0.01
I1024 01:29:34.530696 37954 solver.cpp:228] Iteration 8680, loss = 1.46473
I1024 01:29:34.530864 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21325 (* -0.35 = -0.424637 loss)
I1024 01:29:34.530874 37954 solver.cpp:244]     Train net output #1: loss_p2 = 2.90673 (* 0.65 = 1.88937 loss)
I1024 01:29:34.530879 37954 sgd_solver.cpp:106] Iteration 8680, lr = 0.01
I1024 01:30:23.185907 37954 solver.cpp:228] Iteration 8720, loss = 1.62646
I1024 01:30:23.186072 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21249 (* -0.35 = -0.42437 loss)
I1024 01:30:23.186081 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.15513 (* 0.65 = 2.05083 loss)
I1024 01:30:23.186087 37954 sgd_solver.cpp:106] Iteration 8720, lr = 0.01
I1024 01:31:11.820650 37954 solver.cpp:228] Iteration 8760, loss = 1.45274
I1024 01:31:11.820817 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.20956 (* -0.35 = -0.423347 loss)
I1024 01:31:11.820827 37954 solver.cpp:244]     Train net output #1: loss_p2 = 2.88629 (* 0.65 = 1.87609 loss)
I1024 01:31:11.820833 37954 sgd_solver.cpp:106] Iteration 8760, lr = 0.01
I1024 01:32:00.449988 37954 solver.cpp:228] Iteration 8800, loss = 1.48626
I1024 01:32:00.450157 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.20908 (* -0.35 = -0.423177 loss)
I1024 01:32:00.450166 37954 solver.cpp:244]     Train net output #1: loss_p2 = 2.9376 (* 0.65 = 1.90944 loss)
I1024 01:32:00.450173 37954 sgd_solver.cpp:106] Iteration 8800, lr = 0.01
I1024 01:32:49.094555 37954 solver.cpp:228] Iteration 8840, loss = 1.61701
I1024 01:32:49.094738 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.20953 (* -0.35 = -0.423335 loss)
I1024 01:32:49.094746 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.139 (* 0.65 = 2.04035 loss)
I1024 01:32:49.094753 37954 sgd_solver.cpp:106] Iteration 8840, lr = 0.01
I1024 01:33:37.754601 37954 solver.cpp:228] Iteration 8880, loss = 1.48454
I1024 01:33:37.754768 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.20554 (* -0.35 = -0.421938 loss)
I1024 01:33:37.754778 37954 solver.cpp:244]     Train net output #1: loss_p2 = 2.93304 (* 0.65 = 1.90648 loss)
I1024 01:33:37.754783 37954 sgd_solver.cpp:106] Iteration 8880, lr = 0.01
I1024 01:34:26.397965 37954 solver.cpp:228] Iteration 8920, loss = 1.53008
I1024 01:34:26.398131 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.21296 (* -0.35 = -0.424535 loss)
I1024 01:34:26.398140 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.0071 (* 0.65 = 1.95462 loss)
I1024 01:34:26.398146 37954 sgd_solver.cpp:106] Iteration 8920, lr = 0.01
I1024 01:35:15.052795 37954 solver.cpp:228] Iteration 8960, loss = 1.58799
I1024 01:35:15.052939 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.20841 (* -0.35 = -0.422944 loss)
I1024 01:35:15.052949 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.09374 (* 0.65 = 2.01093 loss)
I1024 01:35:15.052955 37954 sgd_solver.cpp:106] Iteration 8960, lr = 0.01
I1024 01:36:02.467013 37954 solver.cpp:454] Snapshotting to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_9000.caffemodel
I1024 01:36:08.115064 37954 sgd_solver.cpp:273] Snapshotting solver state to binary proto file models/dissimilarity_siamese_net/snapshots/caffe_alexnet_train_iter_9000.solverstate
I1024 01:36:10.917698 37954 solver.cpp:337] Iteration 9000, Testing net (#0)
I1024 01:38:04.572926 37954 solver.cpp:404]     Test net output #0: accuracy = 0.1076
I1024 01:38:04.573153 37954 solver.cpp:404]     Test net output #1: loss_p1 = 1.3042 (* -0.35 = -0.456469 loss)
I1024 01:38:04.573161 37954 solver.cpp:404]     Test net output #2: loss_p2 = 4.94021 (* 0.65 = 3.21113 loss)
I1024 01:38:05.113380 37954 solver.cpp:228] Iteration 9000, loss = 1.55637
I1024 01:38:05.113435 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.20797 (* -0.35 = -0.42279 loss)
I1024 01:38:05.113442 37954 solver.cpp:244]     Train net output #1: loss_p2 = 3.04486 (* 0.65 = 1.97916 loss)
I1024 01:38:05.113451 37954 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I1024 01:38:54.068892 37954 solver.cpp:228] Iteration 9040, loss = 1.49499
I1024 01:38:54.069151 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.20819 (* -0.35 = -0.422866 loss)
I1024 01:38:54.069161 37954 solver.cpp:244]     Train net output #1: loss_p2 = 2.95055 (* 0.65 = 1.91786 loss)
I1024 01:38:54.069170 37954 sgd_solver.cpp:106] Iteration 9040, lr = 0.01
I1024 01:39:43.037302 37954 solver.cpp:228] Iteration 9080, loss = 1.44063
I1024 01:39:43.037566 37954 solver.cpp:244]     Train net output #0: loss_p1 = 1.20571 (* -0.35 = -0.421999 loss)
I1024 01:39:43.037576 37954 solver.cpp:244]     Train net output #1: loss_p2 = 2.86558 (* 0.65 = 1.86263 loss)
I1024 01:39:43.037586 37954 sgd_solver.cpp:106] Iteration 9080, lr = 0.01
